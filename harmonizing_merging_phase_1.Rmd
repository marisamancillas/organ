---
title: 'Herbaria Data Harmonizing and Cleaning Phase 1'
author: "Marisa Mancillas"
date: "Last updated: 12/08/2022"
output: 
  html_document:
    toc: true
    number_sections: true
    toc_float:  
      theme: cosmo
      highlight: tango 
---
# Introduction

## Background
This workflow was created to address the needs of an ongoing research project at the New Mexico State University investigating plant species in the Organ Mountains of south-central New Mexico. This project draws from historical ecology, botany, ecology, and biogeography disciplines to understand how plant species may be responding to climate and land use change over time. The Organ Mountains are a model system for understanding plant species response to climate and land use change.

## Objectives:
The goal of this script was to harmonize plant species occurrence data across several herbaria and biodiversity repositories for the Organ Mountains (-106.6418 W, 32.1589 N, -106.4665 W, 32.42757 N) from the first specimen collection record in 1848 to February 2021. Specific objectives were to (1) Subset the occurrence records for the Organ Mountains both for georeferenced and non-georefereneced records (2) Identify duplicate records and harmonize all information for that individual collection event within and between institutions and (3) Standardize schema and combine all occurrences into one dataset.

## Database Queries 
To obtain the most complete set of plant species occurrence data through time we queried herbarium databases at [The New Mexico State University (NMC–NMCR 2021)](https://herbarium.nmsu.edu/index.html) herbaria, [Consortia of Intermountain Regional Herbaria (Intermountain Region Herbarium Network 2021)](https://intermountainbiota.org/portal/collections/index.php), [The Global Biodiversity Information Facility](https://www.gbif.org)(GBIF 2021), [The Southwest Environmental Network (SEINet)](https://swbiodiversity.org/seinet/) (SEINet Portal Network 2021), [The Smithsonian National Museum of Natural History](https://collections.nmnh.si.edu/search/botany/) (Smithsonian National Museum of Natural History Department of Botany Collections 2021), and [The University of Texas in El Paso Biodiversity Collections](https://www.utep.edu/biodiversity/collections/herbarium.html) (UTEP 2021). Collectively these sources draw from 138 herbaria from 135 institutions in North America (N = 120), Europe (N = 7), Mexico (N = 4), Australia (N = 3), Asia (N = 2), Cuba (N = 1), and New Zealand (N = 1).  

Our query included the Doña Ana County geographic area and all New Mexico counties starting with the letter “d” to allow for spelling errors and non-georeferenced records. Occurrences with coordinate locations within our defined spatial extent of the Organ Mountains (-106.6418 W, 32.1589 N, -106.4665 W, 32.42757 N) were extracted by location and non-georeferenced occurrences were retained based on a string search for Organ Mountain locality placenames. The data were then cleaned, harmonized, and normalized into related tables in the Rmd file entitled "harmonizing_merging_phase_2.Rmd".

## Oragnization of this Document

For each of the six datasets, the same primary activities were preformed to meet our objectives. First, the dataset was brought in and some minor cleaning was preformed (e.g., changing names and data structure). Second, georeferenced data were subset by location and non-georeferenced records were subset based on matching a series of fuzzy search terms thought to match most organ mountain place names. Third, collector names were standardized using a dictionary of regular expression search patterns and the corresponding cleaned collector name ("./dictionaries/collector_name_dictionary.csv"). Forth, duplicates were identified using a combination of the cleaned collector name, date, species name, and location description. When these fields matched exactly, the record was given a duplicate ID and all of the information from all fields were concatenated row-wise. This means that if there were 10 duplicates, but some institutions have provided a georeferenced locality, this would be retained along with metadata only entered in another institution. Finally, the data schema was standardized using our column name dictionary ("./dictionaries/column_name_dictionary.csv") and all datasets were combined by row. Modifications to these basic steps were taken due to differences in schema between datasets. A brief description is provided at the beginning of each dataset including a full citaton and link to the data download when available.

# Setup

## Packages

```{r set up, message = FALSE, warning = FALSE}
# packages used
library(tidyverse)
library(data.table)
library(parzer)
library(matchmaker)
library(janitor)
library(sf)
library(gdata)

knitr::opts_chunk$set(warning = FALSE, message = FALSE)
devtools::session_info()
```

##  Functions
```{r functions}
# housekeeping function
# This function changes the structure of all fields into lowercase, character strings,
# then reduce spaces in between and on the edges of strings
housekeeping<-function(df){
df[] <- lapply(df, as.character) # all as character
df <- df %>% mutate_if(is.character, str_to_lower) -> df # all lowercase
df <- df %>%
  mutate_if(is.character, str_squish) %>% # trim repeated spaces in-between strings
  mutate_if(is.character, str_trim, side = "both") %>% # trim empty spaces on string edges
  mutate_all(na_if,"") # all blanks to NA
return(df)
}

# str_squish_trim function: strim squish and string trim at same time
str_squish_trim<-function(df){
df <- df %>%
  mutate_if(is.character, str_squish) %>% # trim repeated spaces in-between strings
  mutate_if(is.character, str_trim, side = "both") # trim empty spaces on string edges
}

# conditional_dupes function allows you to harmonize rows which are duplicated in different sets of columns
conditional_dupes <- function(na,df,location,eventdate,clean.collector,taxon,colnumber)
  {
  if(na == "TRUE") {
   df <- df %>% 
     get_dupes(clean.collector, eventdate, colnumber, taxon)
  } else {
   df <-  df %>% get_dupes(clean.collector, location, eventdate, 
                           colnumber, taxon)
  }
  return(df)
}


# paste and ignore NA values
paste_na <- function(..., sep = " ") {
  L <- list(...)
  L <- lapply(
    L,
    function(x) {
      x[is.na(x)] <- ""
      x
    }
  )
  out <- gsub(
    paste0("(^", sep, "|", sep, "$)"), "",
    gsub(
      paste0(sep, sep), sep,
      do.call(paste, c(L, list(sep = sep)))
    )
  )
  is.na(out) <- out == ""
  return(out)
}

# paste distinct values while ignoring NA
paste_distinct <- function(list){
    list %>% unique %>% sort %>% paste_na(collapse = ",")
}

# function to subset data based on organ mountains boundary
organ_location <- function(polygon, sfdata)
  {
  polygon <- st_as_sf(polygon) # 
  st_crs(sfdata) <- st_crs(polygon) # makes coordinate reference systems equivalent
  polygon <- st_make_valid(polygon) # makes geometry valid
  ogeo <- st_intersection(sfdata, polygon)
  ogeo <- ogeo %>%
  dplyr::mutate(longitude = sf::st_coordinates(.)[,1],
                latitude = sf::st_coordinates(.)[,2]) %>% 
  st_drop_geometry(ogeo) %>% 
  dplyr::select(-c(id))
  return(ogeo)
}

# function to harmonize duplicates row-wise allowing flexible selection of 
# columns from which to identify duplicates
my_mutate_distinct <- function(data, group_vars, summary_vars, ...) {
  stopifnot(
    is.list(group_vars),
    is.list(summary_vars)
  )
  
  args <- enquos(...)
  ex_args <- unname(imap(args, function(expr, name) quo(!!sym(name)==!!expr)))

  # Detect and prefix unnamed arguments:
  unnamed <- names(summary_vars) == ""

  # Add the default names:
  summary_vars <- rlang::quos_auto_name(summary_vars)

  prefixed_nms <- paste0("new_", names(summary_vars)[unnamed])
  names(summary_vars)[unnamed] <- prefixed_nms

  # Expand the argument _after_ giving the list its default names
  summary_vars <- purrr::map(summary_vars, function(var) {
    expr(paste_distinct(!!var))
  })

  data %>%
    group_by(!!!group_vars) %>%
    filter(!!!ex_args) %>% 
    mutate(n = n(), !!!summary_vars) %>% 
    fill(everything(), .direction = "down") %>%
    fill(everything(), .direction = "up")
}
```

# Harmonizing

## NMC-NMCR Herbarium

NMC–NMCR (2021). New Mexico State University Herbarium (NMC–NMCR). Biodiversity occurrence data for Doña Ana County. 2022 January 19 

```{r NMC-NMCR data}
df <- read.csv("./repo_herb_original/NMSU_herbaria_Dona_Ana_1.19.2022.csv", header = TRUE)

# add primary key
df$myid <- paste0(df$myid,'nmsu', seq.int(nrow(df)))

# subset columns
df <- df[ c(1,2,10,13,14,15,16,21,22,39:88,94:96,101:104,126:129,144)] 

# housekeeping and add prefix
df <- df %>% housekeeping() %>% 
  rename_with( ~ paste("OG", .x, sep = "_"))
```

```{r NMC-NMCR duplicates}
# Create duplicate count for select columns and create dupe ID
dfdupe <- df %>% 
  get_dupes(OG_AccessionNumber) %>% 
  mutate(within_inst_dupe_id = group_indices(., OG_AccessionNumber)) 

# dupe prefix id
dfdupe$within_inst_dupe_id <- paste0('wi_nmsu_', dfdupe$within_inst_dupe_id)

# Harmonize row-wise filling all NA values
df <- df %>% 
  group_by(OG_AccessionNumber) %>% 
  fill(everything(), .direction = "down") %>%
  fill(everything(), .direction = "up") %>%
  slice(1)

# Create table tracking duplication
dupe_table <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, OG_myid, dupe_count, OG_HerbariumAcronyms) %>% 
  rename(institution = OG_HerbariumAcronyms, 
         og_myid= OG_myid)
```

```{r NMC-NMCR blm}
# Bring in Organ Mountain dataset
df1 <- read.csv("./repo_herb_original/OMBLM.csv", header = TRUE)
df1$myid <- paste0(df1$myid, 'nmsublm',seq.int(nrow(df1))) # ID

df1 <- housekeeping(df1) # housekeeping
names(df)[1] <- "AccessionNumber" # rename in order to join
df <- left_join(df1,df, by = "AccessionNumber") # join both by AccessionNumber
df <- df[ c(1:48,73:78,83,84,107:118)] # subset
```

```{r NMC-NMCR coalesce}

# Records georeferenced using township range and section are most accurate for oldest records, followed by decimal minutes from UTM, then post-factum georeferencing 
# Here I am coalescing columns to prioritize the more accurate georeferencing
df <- df %>% 
  mutate(latitude = coalesce(OG_CalculatedLatitudeInDecimalMinutesFromTRS,
                           OG_CalculatedLatitudeInDecimalMinutesFromUTM,
                           DecDeg_Verb.Post_Factum_Latitude, LATITUDE)) %>% 
  mutate(longitude = coalesce(OG_CalculatedLongitudeInDecimalMinutesFromTRS,
                            OG_CalculatedLongitudeInDecimalMinutesFromUTM,
                            DecDeg_Verb.Post_Factum_Longitude, LONGITUDE)) %>% 
  rename(day = OG_CollectingStartDateDay,
         month = OG_CollectingStartDateMonth,
         year = OG_CollectingStartDateYear) %>% 
  mutate(collector = paste(df$OG_Collector1FirstName,df$OG_Collector1MiddleName, 
                           df$OG_Collector1LastName, sep= " ")) %>% 
  dplyr::select( -c(LATITUDE, OG_Latitude, DecDeg_Verb.Post_Factum_Latitude, LONGITUDE,
           OG_Longitude, DecDeg_Verb.Post_Factum_Longitude,
           OG_CalculatedLatitudeInDecimalMinutesFromUTM, 
           OG_CalculatedLatitudeInDecimalMinutesFromTRS,Collector, 
           OG_LatitudeRemark,OG_LongitudeRemark, OG_CollectionNumberAlphanumeric,
           OG_Collector1FirstName, OG_Collector1MiddleName,OG_Collector1LastName, 
           OG_LegacyDuplicateDistributionString, OG_DuplicateNumberOriginal, 
           MERIDIAN_FOR_TRS_CALC, TOWNSHIP_STANDARDIZED, RANGE_STANDARDIZED,
           SECTION_STANDARDIZED, Q_STANDARDIZED, Q1_STANDARDIZED, Q2_STANDARDIZED,
           TRS_TEXT_NOTE_STANDARDIZED,UTM_DATUM_STANDARDIZED, UTM_E_STANDARDIZED,
           UTM_N_STANDARDIZED, UTM_Z_STANDARDIZED, 
           OG_CalculatedLatitudeInDecimalMinutesFromTRS,
           OG_CalculatedLatitudeInDecimalMinutesFromUTM))

# column names to lowercase
names(df) <- tolower(names(df))
```

```{r NMC-NMCR georeferenced, message = FALSE, warning = FALSE}
# Clean latitude and longitude columns
df$latitude <- parse_lat(df$latitude)
df$longitude <- parse_lon(df$longitude)

# filter out non-georeferenced records
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))
sfpoly <- st_read("./organ_mountain_shapefile")

# subset by location
ogeo <- organ_location(sfpoly, sfdf)
```

```{r NMC-NMCR non-georeferenced}
# Keep rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))

# Filter Non-Georeferenced records by string match
onotgeo <- notgeo %>% 
  filter_at(vars(location, abiotic_ecological, biotic_association, query_word, og_collectionremarksgeneral),
  any_vars(str_detect(.,".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

# Order names and bind non-georeferenced and georeferenced records together
ogeo <- ogeo[,order(names(ogeo))]
onotgeo <- onotgeo[,order(names(onotgeo))]
org <- rbind(onotgeo, ogeo)

# rename
df <- org
```

```{r NMC-NMCR collector names}
# replace various strings indicating NA as NA
df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)

# Get rid of spaces again
df <- str_squish_trim(df)

# Remove "NA NA NA"
df$collector <- df$collector %>%
  str_remove("NA ") %>% 
  str_remove("NA") %>%
  str_remove("NA")

# Reduce spaces again
df <- str_squish_trim(df)

# Fill NA's Back in and duplicate column
df <- df %>% 
  mutate_all(na_if,"") %>% 
  mutate(clean.collector = collector)

# Since the NMC-NMCR names are already very clean, I'm only modifying a 
# few so they match the collector name dictionary
df$clean.collector <- gsub("^bruce.*weber", "bruce e. weber", df$clean.collector)
df$clean.collector <- gsub("c. (mrs.) t. bartlett", "c. t. bartlett", df$clean.collector) 
df$clean.collector <- gsub("c. e. freeman", "craig freeman", df$clean.collector) 
df$clean.collector <- gsub(".*ulaszek", "eric f. ulaszek", df$clean.collector) 
df$clean.collector <- gsub(".*coons", "f. m. coons", df$clean.collector) 
df$clean.collector <- gsub(".*medler", "john medler", df$clean.collector) 
df$clean.collector <- gsub("^r. c. j.$", "raymond c. jackson", df$clean.collector) 
df$clean.collector <- gsub(".*anderson", "s. e. anderson", df$clean.collector) 

```


```{r NMC-NMCR blm dupelicates}
df <- df %>% 
  rename(eventdate = collection_date,
         colnumber = calc_coll_number)

# Generate duplicate count for select columns and create a duplicate ID
dfdupe <- df %>% 
  get_dupes(clean.collector, colnumber, location, eventdate, taxon, latitude, longitude) %>% 
  mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, location, 
                                   eventdate, taxon, latitude, longitude))


# dupe prefix id
dfdupe$within_inst_dupe_id <- paste0('wi_nmsublm_', dfdupe$within_inst_dupe_id)

# subeset previous duplicate table to only include those in organ filtered data
dupe_table <- semi_join(dupe_table, df, by = 'og_myid')

# Create another table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, og_herbariumacronyms) %>% 
  rename(institution = og_herbariumacronyms)

# rename to merge
dupe_table <- dupe_table %>% 
  rename(myid = og_myid)

# bind the two dupelicate tables
dupe_table <- rbind(dupe_table_1, dupe_table)

# replace NA's with nmc 
dupe_table$institution <- dupe_table$institution %>% replace_na('nmc')

# add data_source column
dupe_table$data_source <- "nmsu"
```

```{r NMC-NMCR blm harmonize}
# Harmonize row-wise based on unique duplicate ID
dfdupemerge <- dfdupe %>%
  group_by(within_inst_dupe_id) %>%
  fill(everything(), .direction = "down") %>%
  fill(everything(), .direction = "up") %>% 
  slice(1)

# Anti_join so that the main dataframe only has non duplicated records
df <- anti_join(df, dfdupe, by = 'myid') 
df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates

# Merge
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]
df <- rbind(df,dfdupemerge)
```

 Standardize Schema

```{r NMC-NMCR schema}
dictionary <- read.csv("./dictionaries/column_name_dictionary.csv", header = TRUE)
colnames <- names(df) 
colnames <- as.data.frame(colnames) # as dataframe

colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

# rename dataframe based on fixed colnames
names(df) <- colnames$colnames 
# delete columns named "drop"
df <- df[ , -which(names(df) %in% c("drop"))] 
nmsu <- df #rename

# keep these objects
keep(nmsu, dupe_table, sfpoly, dictionary, organ_location, housekeeping, 
     str_squish_trim, conditional_dupes, my_mutate_distinct, paste_na, 
     paste_distinct, sure = TRUE)


```

## Consortia of Intermountain Regional Herbaria Network

Intermountain Region Herbarium Network (2021) Biodiversity occurrence data published via SEINet, accessed via https://intermountainbiota.org. 2021 February 02 

```{r COIH data}
df <- read.csv("./repo_herb_original/coih_original.csv", header = TRUE)
df$myid <- paste0(df$myid,'coih',seq.int(nrow(df)))

# housekeeping
df <- housekeeping(df)
df <- df[,colSums(is.na(df))<nrow(df)] # drop columns which are all NA
```

 Separate Georeferenced Records
```{r COIH georeferenced}

df <- df %>% rename(longitude = decimalLongitude,
       latitude = decimalLatitude) %>% 
  dplyr::select(-c(id))

# Retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

# parse lat long
geo$latitude <- parse_lat(geo$latitude)
geo$longitude <- parse_lon(geo$longitude)

# drop NA
geo <- geo[!is.na(geo$latitude), ]
geo <- geo[!is.na(geo$longitude), ]

# subset by location
sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))
ogeo <- organ_location(sfpoly, sfdf)
```

 Separate Non-Georeferenced Records 
```{r COIH non-georeferenced, warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))

onotgeo <- notgeo %>% 
  filter_at(vars(locality, locationRemarks, occurrenceRemarks, 
                 verbatimAttributes, municipality, associatedTaxa), 
  any_vars(str_detect(., ".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

# merge
ogeo <- ogeo[,order(names(ogeo))]
onotgeo <- onotgeo[,order(names(onotgeo))]
org <- rbind(onotgeo, ogeo)
```

```{r COIR collector names}
# rename
df <- org

dict <- read.csv("./dictionaries/collector_name_dictionary.csv", header = TRUE) # read in collector dictionary

# rename
df <- df %>% 
  dplyr::rename(taxon = scientificName,
         location = locality,
         eventdate = eventDate,
         colnumber = recordNumber,
         collector = recordedBy)

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

# assign NA where appropriate 
df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)
# housekeeping
df <- housekeeping(df)

# Apply collector name dictionary
df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) 

df$clean.collector <- gsub("\\d.*", "NA", df$clean.collector) # clean
```


```{r COIH flag duplicates, warning = FALSE, message = FALSE, error = TRUE}
# create a column which indicates if the location description is blank. This will help me identify duplicates without erroneously assigning a dupliacte to a column which is duplicated only becasue of the "NA" in location
df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

# assign duplicates based on duplication in collector, date, collection number, and taxon
# but separate those that have NA's in the location - we don't want to group these as duplicates if they have no locality description
dfdupe <- conditional_dupes(na = df$na, df = df, df$location,  df$eventdate,
               df$clean.collector, df$taxon, df$colnumber)

# Duplicate ID
dfdupe <- dfdupe %>% 
  group_by(clean.collector, colnumber,eventdate, taxon, year) %>%  # group by this
    mutate(within_inst_dupe_id = cur_group_id())%>%  # make an id based on the grouping
  group_by(within_inst_dupe_id) %>% # group by id
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE))%>% # count georeferencing efforts
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything()) # bring this to the front

# make the duplicate id unique for coih
dfdupe$within_inst_dupe_id <- paste0('wi_coih_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, institutionCode) %>% 
  rename(institution = institutionCode)

# add data_source column
dupe_table_1$data_source <- "coih"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)
```

```{r COIH harmonize duplicates}

# using my function to select duplicate criteria and 
# keep all information from all rows from that duplicate
# and harmonize into one one record (one row)

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
  vars(associatedCollectors = associatedCollectors, 
       associatedTaxa = associatedTaxa, 
       collectionCode = collectionCode,
       cultivationStatus = cultivationStatus,
       dateIdentified = dateIdentified, 
       day = day, 
       endDayOfYear = endDayOfYear, 
       establishmentMeans = establishmentMeans, 
       georeferenceRemarks = georeferenceRemarks, 
       habitat = habitat, 
       identificationQualifier = identificationQualifier,
       identificationRemarks = identificationRemarks, 
       identifiedBy = identifiedBy,
       locationRemarks = locationRemarks, 
       month = month, 
       occurrenceRemarks = occurrenceRemarks,
       reproductiveCondition = reproductiveCondition, 
       startDayOfYear = startDayOfYear, 
       substrate = substrate, verbatimAttributes = verbatimAttributes,
       verbatimCoordinates = verbatimCoordinates, 
       verbatimElevation = verbatimElevation, 
       verbatimEventDate = verbatimEventDate,year = year,
       specificEpithet = specificEpithet, 
       taxonRemarks = taxonRemarks, municipality = municipality, 
       lifeStage = lifeStage,
       individualCount = individualCount, 
       dynamicProperties = dynamicProperties, 
       disposition = disposition, collId = collId, 
       minimumElevationInMeters = minimumElevationInMeters,
       maximumElevationInMeters = maximumElevationInMeters, 
       georeferenceProtocol= georeferenceProtocol,
       georeferenceSources = georeferenceSources, 
       georeferenceVerificationStatus = georeferenceVerificationStatus,
       scientificNameAuthorship = scientificNameAuthorship, 
       infraspecificEpithet = infraspecificEpithet, 
       collector = collector, myid = myid, 
       institutionCode = institutionCode,
       otherCatalogNumbers = otherCatalogNumbers,
       ownerInstitutionCode = ownerInstitutionCode,
       catalogNumber = catalogNumber), loc_count = '0') %>% slice(1)

dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
  vars(associatedCollectors = associatedCollectors, 
       associatedTaxa = associatedTaxa, 
       collectionCode = collectionCode,
       cultivationStatus = cultivationStatus,
       dateIdentified = dateIdentified, 
       day = day, endDayOfYear = endDayOfYear,
       establishmentMeans = establishmentMeans, 
       georeferenceRemarks = georeferenceRemarks, 
       habitat = habitat, 
       identificationQualifier = identificationQualifier,
       identificationRemarks = identificationRemarks, 
       identifiedBy = identifiedBy,
       locationRemarks = locationRemarks, month = month, 
       occurrenceRemarks = occurrenceRemarks,
       reproductiveCondition = reproductiveCondition, 
       startDayOfYear = startDayOfYear, substrate = substrate, 
       verbatimAttributes = verbatimAttributes,
       verbatimCoordinates = verbatimCoordinates, 
       verbatimElevation = verbatimElevation, 
       verbatimEventDate = verbatimEventDate,year = year,
       specificEpithet = specificEpithet, 
       taxonRemarks = taxonRemarks, municipality = municipality, 
       lifeStage = lifeStage,
       individualCount = individualCount, 
       dynamicProperties = dynamicProperties, 
       disposition = disposition, collId = collId, 
       minimumElevationInMeters = minimumElevationInMeters,
       maximumElevationInMeters = maximumElevationInMeters, 
       georeferenceProtocol= georeferenceProtocol,
       georeferenceSources = georeferenceSources, 
       georeferenceVerificationStatus = georeferenceVerificationStatus,
       scientificNameAuthorship = scientificNameAuthorship, 
       infraspecificEpithet = infraspecificEpithet, 
       collector = collector, myid = myid, institutionCode = institutionCode, 
       otherCatalogNumbers = otherCatalogNumbers,
       ownerInstitutionCode = ownerInstitutionCode),
  loc_count = '1') %>% 
  filter(!is.na(latitude)) %>% slice(1)

dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

# bine duplicates together
dfdupemerge <- rbind(dupe1,dupe2,dupe3)
```


```{r COIH merge harmonized records}
df <- anti_join(df, dfdupe, by = 'myid') # anti_join so dataframe does not include duplicates
df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA" 
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]

dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))
# bind
df <- rbind(df,dfdupemerge)
```

 Standardize Schema
```{r COIH schema, warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
coih <- df #rename

keep(coih, nmsu, dupe_table, sfpoly, dictionary, dict, organ_location, 
     housekeeping, str_squish_trim, conditional_dupes,
     my_mutate_distinct, paste_na, paste_distinct, sure = TRUE)
```

## Global Biodiversity Information Facility

GBIF.org (02 February 2021) GBIF Occurrence Download https://doi.org/10.15468/dl.4cw65k 

```{r GBIF data, warning = FALSE, message = FALSE}
df <- read.csv("./repo_herb_original/gbif_original.csv", header = TRUE)
# primary key
df$myid <- paste0(df$myid,'gbif',seq.int(nrow(df)))
# housekeeping and renaming
df <- df %>% housekeeping() %>% 
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude,
         collector = recordedBy,
         taxon = scientificName,
         location = locality,
         eventdate = eventDate,
         colnumber = recordNumber)
```
 Separate Georeferenced Records
```{r GBIF georeferenced, warning = FALSE, message = FALSE}
#retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

geo$latitude <- parse_lat(geo$latitude)
geo$longitude <- parse_lon(geo$longitude)

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))

ogeo <- organ_location(sfpoly, sfdf)
```

 Separate Non-Georeferenced Records
```{r GBIF non-georeferenced, warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))

onotgeo <- notgeo %>% 
  filter_all(all_vars(str_detect(.,".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))
```

 Clean Collector Names With Dictionary
```{r GBIF collector names, warning = FALSE, message = FALSE}
df <- ogeo

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)

df <- housekeeping(df)

df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) # apply collector name dictionary
```


```{r GBIF flag dupelicates, warning = FALSE, message = FALSE}
df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

dfdupe <- conditional_dupes(na = df$na, df = df, df$location, df$eventdate, 
               df$clean.collector, df$taxon, df$colnumber)

dfdupe <- dfdupe %>% 
    mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, year, location, 
                                   eventdate, taxon)) %>% 
  group_by(within_inst_dupe_id) %>%
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE)) %>% 
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything())

dfdupe$within_inst_dupe_id <- paste0('wi_gbif_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, institutionCode) %>% 
  rename(institution = institutionCode)

# add data_source column
dupe_table_1$data_source <- "gbif"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)
```

```{r GBIF harmonize duplicates, warning = FALSE, message = FALSE}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(dateIdentified = dateIdentified,day = day,
                                 elevation = elevation,
                                 elevationAccuracy = elevationAccuracy,
                                 establishmentMeans = establishmentMeans,
                                 identifiedBy = identifiedBy,
                                 individualCount = individualCount,
                                 issue = issue,lastInterpreted = lastInterpreted,
                                 mediaType = mediaType,month = month,collector = collector,
                                 verbatimScientificName = verbatimScientificName,
                                 verbatimScientificNameAuthorship = verbatimScientificNameAuthorship,
                                 year = year,
                                 rightsHolder = rightsHolder,license = license,infraspecificEpithet = infraspecificEpithet,
                                 myid = myid,institutionCode = institutionCode,collectionCode = collectionCode,
                                 catalogNumber = catalogNumber), loc_count = '0') %>% slice(1)

# if one lat long and one NA keep the lat long for everything
dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(dateIdentified = dateIdentified,day = day,
                                 elevation = elevation,elevationAccuracy = elevationAccuracy,
                                 establishmentMeans = establishmentMeans,identifiedBy = identifiedBy,
                                 individualCount = individualCount,issue = issue,lastInterpreted = lastInterpreted,
                                 mediaType = mediaType,month = month,collector = collector,
                                 verbatimScientificName = verbatimScientificName,
                                 verbatimScientificNameAuthorship = verbatimScientificNameAuthorship,year = year,
                                 rightsHolder = rightsHolder,license = license,infraspecificEpithet = infraspecificEpithet,
                                 myid = myid,institutionCode = institutionCode,collectionCode = collectionCode,
                                 catalogNumber = catalogNumber), loc_count = '1') %>% 
  filter(!is.na(latitude)) %>% 
  slice(1) 

dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)

df <- anti_join(df, dfdupe, by = 'myid') 
df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"

dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

# merge
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]
df <- rbind(df,dfdupemerge)
```

 Standardize Schema
```{r GBIF schema, warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
gbif <- df #rename
keep(sfpoly, coih, nmsu,gbif, dupe_table, dictionary, dict, 
     organ_location, housekeeping, str_squish_trim, 
     conditional_dupes,my_mutate_distinct, paste_na, paste_distinct, 
     sure = TRUE)
```

## SEINET

SEINet Portal Network (2021) Biodiversity occurrence data published via SEINet accessed via http//:swbiodiversity.org. 2021 February 07 
```{r SEINET data, warning = FALSE, message = FALSE}
df <- read.csv("./repo_herb_original/seinet_original_copy.csv", header = TRUE) 
df$myid <- paste0(df$myid,'seinet',seq.int(nrow(df))) # add personal ID
# housekeeping
df <- df %>% housekeeping() %>% 
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude, 
         collector = recordedBy,
         taxon = scientificName_occurrence,
         location = locality,
         eventdate = eventDate,
         colnumber = recordNumber)
```

 Separate Georeferenced Records
```{r SEINET georeferenced, warning = FALSE, message = FALSE}
#retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

geo <- geo[!is.na(geo$latitude), ] # drop all NA for latitude
geo <- geo[!is.na(geo$longitude), ] # drop all NA for longitude

geo$latitude <- parse_lat(geo$latitude) # parse / clean lat
geo$longitude <- parse_lon(geo$longitude) # parse / clean long

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))

ogeo <- organ_location(sfpoly, sfdf)
```

 Separate Non-Georeferenced Records 
```{r SEINET non-georeferenced, warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.))) # filter for records without lat long

onotgeo <- notgeo %>% 
  filter_at(vars(location, municipality, occurrenceRemarks, habitat), 
  any_vars(str_detect(.,".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

ogeo <- ogeo[,order(names(ogeo))] # order columns alphabetically
onotgeo <- onotgeo[,order(names(onotgeo))] # order columns alphabetically

# bind
org <- rbind(onotgeo, ogeo) 
```

 Clean Collector Names With Dictionary
```{r SEINET collector names, warning = FALSE, message = FALSE}
df <- org

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)

df <- housekeeping(df)

df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) # apply collector name dictionary

df$clean.collector <- gsub("\\d.*", "NA", df$clean.collector) # extra cleaning
```


```{r SEINET flag duplicates, warning = FALSE, message = FALSE}
df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

dfdupe <- conditional_dupes(na = df$na, df = df, df$location, df$eventdate, 
               df$clean.collector, df$taxon, df$colnumber)

dfdupe <- dfdupe %>% 
    mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, location, 
                                   eventdate, taxon))%>% 
  group_by(within_inst_dupe_id) %>%
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE))%>% 
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything())

dfdupe$within_inst_dupe_id <- paste0('wi_seinet_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, institutionCode) %>% 
  rename(institution = institutionCode)

# add data_source column
dupe_table_1$data_source <- "seinet"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)

```

```{r SEINET harmonize duplicates, warning = FALSE, message = FALSE}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(associatedTaxa = associatedTaxa,dateIdentified = dateIdentified,
                                 occurrenceRemarks = occurrenceRemarks,
                                 reproductivecondition = reproductivecondition,
                                 verbatimelevation = verbatimelevation,
                                 habitat = habitat,municipality = municipality,
                                 collector = collector,
                                 reproductivecondition = reproductivecondition,
                                 identifiedBy = identifiedBy,
                                 maximumelevationinmeters = maximumelevationinmeters,
                                 minimumElevationInMeters = minimumElevationInMeters,
                                 localitysecurity = localitysecurity,
                                 coordinateUncertaintyInMeters = coordinateUncertaintyInMeters,
                                 myid = myid,institutionCode = institutionCode,
                                 occid = occid,catalogNumber = catalogNumber,
                                 references = references), loc_count = '0') %>% slice(1)

dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(associatedTaxa = associatedTaxa,dateIdentified = dateIdentified,
                                 occurrenceRemarks = occurrenceRemarks,
                                 reproductivecondition = reproductivecondition,
                                 verbatimelevation = verbatimelevation,
                                 habitat = habitat,municipality = municipality,
                                 collector = collector,
                                 reproductivecondition = reproductivecondition,
                                 identifiedBy = identifiedBy,
                                 maximumelevationinmeters = maximumelevationinmeters,
                                 minimumElevationInMeters = minimumElevationInMeters,
                                 localitysecurity = localitysecurity,
                                 coordinateUncertaintyInMeters = coordinateUncertaintyInMeters,
                                 myid = myid,institutionCode = institutionCode,
                                 occid = occid,catalogNumber = catalogNumber,
                                 references = references), loc_count = '1') %>% 
  filter(!is.na(latitude)) %>% slice(1)

dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)

df <- anti_join(df, dfdupe, by = 'myid') # anti_join so that the main dataframe does not include the duplicates

df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"

df <- df[,order(names(df))] # order columns alphabetically 
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))] # order columns alphabetically 

dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

df <- rbind(df,dfdupemerge)

df <- df %>% 
  filter(!str_detect(county, '^dougl.*')) # remove douglas county records
```

 Standardize Schema
```{r SEINET schema, warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
seinet <- df #rename

keep(seinet, coih, nmsu, gbif, dupe_table, dict, sfpoly, dictionary, 
     organ_location, housekeeping, str_squish_trim, conditional_dupes, 
      my_mutate_distinct, paste_na, paste_distinct, 
     sure = TRUE)
```

## Smithsonian

Smithsonian National Museum of Natural History Department of Botany Collections (2021) Biodiversity occurrence data accessed via https://collections.nmnh.si.edu/search/botany/. 2021 February 07 

```{r SMITH data}
df <- read.csv("./repo_herb_original/smithsonian_original.csv", header = TRUE)
df$myid <- paste0(df$myid,'smith',seq.int(nrow(df)))

# housekeeping and rename
df <- df %>% 
  housekeeping()%>%  
  rename(longitude = Centroid.Longitude,
         latitude = Centroid.Latitude, 
         collector = Collector.s.,
         taxon = Taxonomic.Name..Filed.As...Identified.By...Identification.Date.,
         location = Precise.Locality,
         eventdate = Date.Collected,
         colnumber = Collection.Number)

df <- df[,colSums(is.na(df))<nrow(df)] # remove columns that are all NA's
```
Separate Georeferenced Records
```{r SMITH geroreferenced, warning = FALSE, message = FALSE}
#retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

geo$latitude <- parse_lat(geo$latitude)
geo$longitude <- parse_lon(geo$longitude)

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))
ogeo <- organ_location(sfpoly, sfdf)

```

 Separate Non-Georeferenced Records 
```{r SMITH non-georeferenced, warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))

onotgeo <- notgeo %>% 
  filter_at(vars(location, Notes, Microhabitat.Description, Habit, District.County, Province.State, Biogeographic.Region, Collection.Remarks,Other.Taxonomic.Names..Identification...Identified.By...Date.Identified., Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation.),
  any_vars(str_detect(.,".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

ogeo <- ogeo[,order(names(ogeo))]
onotgeo <- onotgeo[,order(names(onotgeo))]
org <- rbind(onotgeo, ogeo)
```

 Clean Collector Names With Dictionary
```{r SMITH collector names, warning = FALSE, message = FALSE}
df <- org

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)
df <- housekeeping(df)

df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) # apply collector name dictionary
```


```{r SMITH flag duplicates, warning = FALSE, message = FALSE}
df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

dfdupe <- conditional_dupes(na = df$na, df = df, df$location, df$eventdate, 
               df$clean.collector, df$taxon, df$colnumber)

dfdupe <- dfdupe %>% 
    mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, location, 
                                   eventdate, taxon)) %>% 
  group_by(within_inst_dupe_id) %>%
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE))%>% 
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything())

dfdupe$within_inst_dupe_id <- paste0('wi_smith_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count)

# add data_source column
dupe_table_1$data_source <- "smithsonian"
dupe_table_1$institution <- "smithsonian"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)
```

```{r SMITH harmonize duplicates, warning = FALSE, message = FALSE}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(Elevation..m. = Elevation..m.,
                                 Common.Name..Name...Language. = Common.Name..Name...Language.,
                                 Catalog = Catalog,collector = collector,Habit = Habit,
                                 Microhabitat.Description = Microhabitat.Description,
                                 Notes = Notes,
                                 Record.Last.Modified = Record.Last.Modified,
                                 Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation. = Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation.,myid = myid,
                                 Catalog.Number = Catalog.Number,EZID = EZID), loc_count = '0') %>% slice(1)

dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(Elevation..m. = Elevation..m.,
                                 Common.Name..Name...Language. = Common.Name..Name...Language.,
                                 Catalog = Catalog,collector = collector,Habit = Habit,
                                 Microhabitat.Description = Microhabitat.Description,
                                 Notes = Notes,
                                 Record.Last.Modified = Record.Last.Modified,
                                 Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation. = Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation.,myid = myid,
                                 Catalog.Number = Catalog.Number,EZID = EZID), loc_count = '1') %>% 
  filter(!is.na(latitude)) %>% slice(1)

dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)

df <- anti_join(df, dfdupe, by = 'myid')
df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"

# merge
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]

dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

df <- rbind(df,dfdupemerge)
```
 Standardize Schema
```{r SMITH schema, warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
smith <- df #rename

keep(sfpoly,seinet, smith, coih, nmsu, dupe_table, gbif, dict,dictionary, 
     organ_location, housekeeping, str_squish_trim, conditional_dupes, 
     my_mutate_distinct, paste_na, paste_distinct, 
     sure = TRUE)
```

## Universtiy of Texas in El Paso Herbarium
UTEP (2021) University of Texas at El Paso Biodiversity Collections. Biodiversity occurrence data published via Arctos http://arctos.database.museum/saved/1612802606022. 2021 February 07 

Links to search results:
[georeferenced search](https://arctos.database.museum/saved/1643063047101) and
[non-georeferenced search](https://arctos.database.museum/saved/1643063152809)
```{r UTEP data, warning = FALSE, message = FALSE}
df1 <- read.csv("./repo_herb_original/utep_requery_3.csv", header = TRUE) 
df2 <- read.csv("./repo_herb_original/utep_requery_4.csv", header = TRUE) 
df <- rbind(df1,df2)
df$myid <- paste0(df$myid,'utep',seq.int(nrow(df)))
# housekeeping and rename
df <- df <- df %>% 
  housekeeping() %>% 
  dplyr::rename(taxon = SCIENTIFIC_NAME,
         location = SPEC_LOCALITY,
         eventdate = VERBATIM_DATE,
         colnumber = OTHERCATALOGNUMBERS,
         collector = COLLECTORS,
         latitude = DEC_LAT,
         longitude = DEC_LONG)

df <- df[,colSums(is.na(df))<nrow(df)] # remove columns that are all NA's
```

 Separate Georeferenced Records
```{r UTEP georeferenced, warning = FALSE, message = FALSE}
#retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))
geo$latitude <- parse_lat(geo$latitude)
geo$longitude <- parse_lon(geo$longitude)
sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))

ogeo <- organ_location(sfpoly, sfdf)
```

 Separate Non-Georeferenced Records 
```{r UTEP non-georeferenced, warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))

onotgeo <- notgeo %>% 
  filter_at(vars(COLORS, IDENTIFICATION_REMARKS, location, VERBATIM_LOCALITY, ASSOCIATED_SPECIES,LOCALITY_REMARKS, HABITAT, VERBATIM_COORDINATES),
  any_vars(str_detect(.,"'.*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

ogeo <- ogeo[,order(names(ogeo))]
onotgeo <- onotgeo[,order(names(onotgeo))]
org <- rbind(onotgeo, ogeo)
```

 Clean Collector Names With Dictionary
```{r UTEP collector names, warning = FALSE, message = FALSE}
df <- org

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)

df <- housekeeping(df)

df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) # apply collector name dictionary

```


```{r UTEP flag duplicates, warning = FALSE, message = FALSE}

df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

dfdupe <- conditional_dupes(na = df$na, df = df, df$location, df$eventdate, 
               df$clean.collector, df$taxon, df$colnumber)

dfdupe <- dfdupe %>% 
    mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, 
                                   YEAR_COLLECTED,location, 
                                   eventdate, taxon)) %>% 
  group_by(within_inst_dupe_id) %>%
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE))%>% 
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything())

dfdupe$within_inst_dupe_id <- paste0('wi_utep_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, GUID) %>% 
  rename(institution = GUID)

# add data_source column
dupe_table_1$data_source <- "utep"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)
```

```{r UTEP harmonize duplicates, warning = FALSE, message = FALSE}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(ABUNDANCE = ABUNDANCE,
                                 ASSOCIATED_SPECIES = ASSOCIATED_SPECIES,
                                 collector = collector,
                                 ORIG_LAT_LONG_UNITS = ORIG_LAT_LONG_UNITS,
                                 COLORS = COLORS,ELEV_IN_M = ELEV_IN_M,
                                 GEOREFERENCE_SOURCE = GEOREFERENCE_SOURCE,
                                 GEOREFERENCE_PROTOCOL = GEOREFERENCE_PROTOCOL,
                                 HABITAT = HABITAT,
                                 MINIMUM_ELEVATION = MINIMUM_ELEVATION,
                                 IDENTIFICATION_REMARKS = IDENTIFICATION_REMARKS,
                                 IDENTIFIED_BY = IDENTIFIED_BY,
                                 LOCALITY_REMARKS = LOCALITY_REMARKS,
                                 ORIG_ELEV_UNITS = ORIG_ELEV_UNITS,
                                 VERBATIM_COLLECTOR = VERBATIM_COLLECTOR,
                                 VERBATIM_COORDINATES = VERBATIM_COORDINATES,
                                 COORDINATEUNCERTAINTYINMETERS = COORDINATEUNCERTAINTYINMETERS,
                                 DAY_COLLECTED = DAY_COLLECTED,
                                 MAX_ELEV_IN_M = MAX_ELEV_IN_M,
                                 MAXIMUM_ELEVATION = MAXIMUM_ELEVATION,
                                 SCI_NAME_WITH_AUTH = SCI_NAME_WITH_AUTH,
                                 MIN_ELEV_IN_M = MIN_ELEV_IN_M,
                                 MONTH_COLLECTED = MONTH_COLLECTED,
                                 YEAR_COLLECTED = YEAR_COLLECTED,
                                 VERBATIM_LOCALITY = VERBATIM_LOCALITY,
                                 SUBSPECIES = SUBSPECIES,
                                 myid = myid,GUID = GUID,CATALOGNUMBERINT = CATALOGNUMBERINT), 
                            loc_count = '0') %>% slice(1)

dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(ABUNDANCE = ABUNDANCE,
                                 ASSOCIATED_SPECIES = ASSOCIATED_SPECIES,
                                 collector = collector,
                                 ORIG_LAT_LONG_UNITS = ORIG_LAT_LONG_UNITS,
                                 COLORS = COLORS,ELEV_IN_M = ELEV_IN_M,
                                 GEOREFERENCE_SOURCE = GEOREFERENCE_SOURCE,
                                 GEOREFERENCE_PROTOCOL = GEOREFERENCE_PROTOCOL,
                                 HABITAT = HABITAT,
                                 MINIMUM_ELEVATION = MINIMUM_ELEVATION,
                                 IDENTIFICATION_REMARKS = IDENTIFICATION_REMARKS,
                                 IDENTIFIED_BY = IDENTIFIED_BY,
                                 LOCALITY_REMARKS = LOCALITY_REMARKS,
                                 ORIG_ELEV_UNITS = ORIG_ELEV_UNITS,
                                 VERBATIM_COLLECTOR = VERBATIM_COLLECTOR,
                                 VERBATIM_COORDINATES = VERBATIM_COORDINATES,
                                 COORDINATEUNCERTAINTYINMETERS = COORDINATEUNCERTAINTYINMETERS,
                                 DAY_COLLECTED = DAY_COLLECTED,
                                 MAX_ELEV_IN_M = MAX_ELEV_IN_M,
                                 MAXIMUM_ELEVATION = MAXIMUM_ELEVATION,
                                 SCI_NAME_WITH_AUTH = SCI_NAME_WITH_AUTH,
                                 MIN_ELEV_IN_M = MIN_ELEV_IN_M,
                                 MONTH_COLLECTED = MONTH_COLLECTED,
                                 YEAR_COLLECTED = YEAR_COLLECTED,
                                 VERBATIM_LOCALITY = VERBATIM_LOCALITY,
                                 SUBSPECIES = SUBSPECIES,
                                 myid = myid,GUID = GUID,CATALOGNUMBERINT = CATALOGNUMBERINT), 
                            loc_count = '1') %>% filter(!is.na(latitude)) %>% slice(1)


dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)

df <- anti_join(df, dfdupe, by = 'myid') # anti_join so that the main dataframe does not include the duplicates

df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]
dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

df <- rbind(df,dfdupemerge)
```

 Standardize Schema
```{r UTEP schema, warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
utep <- df #rename

keep(dupe_table, seinet, utep, smith, coih, nmsu, gbif, sfpoly, dict, 
     dictionary, organ_location, housekeeping, str_squish_trim, 
     conditional_dupes, my_mutate_distinct, 
     paste_na, paste_distinct, sure = TRUE)
```

# Combine Data Sets
```{r combine all data sets}
df <- rbindlist(list(as.data.frame(nmsu),
                   as.data.frame(gbif),
                   as.data.frame(seinet),
                   as.data.frame(smith),
                   as.data.frame(coih),
                   as.data.frame(utep)),
                  fill=TRUE)

df <- as.data.frame(df)
df <- df[,order(names(df))]

df$myid <- gsub(".*,.*", NA, df$myid)

df <-df %>% 
  mutate(myid = coalesce(myid, within_inst_dupe_id))
```

```{r misc cleaning}
# column names lowercase
names(df) <- tolower(names(df))

# fix dates in this column
df$verbatim_date <- gsub(".*no.*|^s.d.$|^unk.*|^#.*", "NA", df$verbatim_date)

# coalesce and paste to reduce redundant columns
df <- df %>% 
  dplyr::select(-c(na, myid.1)) %>% 
  mutate(taxon = coalesce(taxon, verbatim_sci_name)) %>% 
  mutate(collection_date = coalesce(collection_date, verbatim_date)) %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE)) %>% 
  mutate(phenology = coalesce(phenology, phenology.1)) %>% 
  mutate(id_history = paste_na(df$id_history, df$id_history.1,
                               df$id_history.2)) %>% 
  mutate(misc_notes = paste_na(df$misc_notes, df$misc_notes.1)) %>% 
  mutate(morphological = paste_na(df$morphological,df$misc_notes.2)) %>% 
  dplyr::select( -c(misc_notes.2, id_history.1, id_history.2, notes.1, 
             taxon_key, species_key, dupe_count, phenology.1, misc_notes.1, 
             loc_count, common_name))

write_excel_csv(df, "all_six_institutions_combined.csv")
write_excel_csv(dupe_table, "within_institutions_duplicates.csv")
```



