---
title: 'Herbaria Data Harmonizing and Cleaning'
author: "Marisa Mancillas"
date: "Last updated: 07/16/2022"
output: 
  html_document:
    toc: true
    toc_float: 
      theme: cosmo
      highlight: tango 
---

# Introduction

## Background
This script was developed to integrate plant species occurrence data across multiple herbaria for the Organ Mountains, New Mexico. I did this by querying 4 biodiversity repositories (which simultaneously query across herbaria), and 2 individual herbarium collections. I didn't access these data via an API, but the full citations for the data download are here:

## Data Used
- New Mexico State University Herbarium
  - 
- Consortia of Intermountain Regional Herbaria Network
  - 
- Global Biodiversity Information Facility
  - GBIF.org (02 February 2021) GBIF Occurrence Download [link]https://doi.org/10.15468/dl.4cw65k
- SEINet
  - SEINet Portal Network. 2021. [link]http//:www.swbiodiversity.org/seinet/index.php. Accessed on February 02.
- The Smithsonian
  - 
- Actos via University of Texas in El Paso Herbarium

## Organization of this document
In this script I repeat the same workflow for each data set with some modifications depending on particularities of the dataset. For example, the New Mexico State University Herbarium had two separate occurrence data sets for the Organ Mountains curated for different purposes; thus these two datasets had to be harmonized first before cleaning them

```{r set up, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE) 
path <- "/Users/abe/Desktop/organ_project/clean_harmonize/repo_herb_original_with_id"
            
# packages
library(arsenal)
library(diffdf)
library(tidyverse)
library(data.table)
library(knitr)
library(sp)
library(sf)
library(raster)
library(rgdal)
library(parzer)
library(matchmaker)
library(janitor)
library(gdata)
library(ggplot2)
library(janitor)
library(kableExtra)
library(DiagrammeR)
library(lubridate)
library(taxize)
library(rgbif)
library(inborutils)
library(curl)
library(rentrez)
options(max.print = 10000)
```


These functions should be uploaded to github
```{r functions}
# housekeeping function: transform to character data, lowercase strings,
# then reduce all the spaces in between and on the edges of strings
housekeeping<-function(df){
df[] <- lapply(df, as.character) # all as character
df <- df %>% mutate_if(is.character, str_to_lower) -> df # all lowercase
df <- df %>%
  mutate_if(is.character, str_squish) %>% # trim repeated spaces in-between strings
  mutate_if(is.character, str_trim, side = "both") %>% # trim empty spaces on string edges
  mutate_all(na_if,"") # all blanks to NA
return(df)
}


# str_squish_trim function: strim squish and string trim at same time
str_squish_trim<-function(df){
df <- df %>%
  mutate_if(is.character, str_squish) %>% # trim repeated spaces in-between strings
  mutate_if(is.character, str_trim, side = "both") # trim empty spaces on string edges
}

# harmonize rows which are duplicated in different set of columns
conditional_dupes <- function(na,df,location,eventdate,clean.collector,taxon,colnumber)
  {
  if(na == "TRUE") {
   df <- df %>% 
     get_dupes(clean.collector, eventdate, colnumber, taxon)
  } else {
   df <-  df %>% get_dupes(clean.collector, location, eventdate, 
                           colnumber, taxon)
  }
  return(df)
}


# paste and ignore NA values
paste_na <- function(..., sep = " ") {
  L <- list(...)
  L <- lapply(
    L,
    function(x) {
      x[is.na(x)] <- ""
      x
    }
  )
  out <- gsub(
    paste0("(^", sep, "|", sep, "$)"), "",
    gsub(
      paste0(sep, sep), sep,
      do.call(paste, c(L, list(sep = sep)))
    )
  )
  is.na(out) <- out == ""
  return(out)
}

# paste distinct values while ignoring NA
paste_distinct <- function(list){
    list %>% unique %>% sort %>% paste_na(collapse = ",")
}

organ_location <- function(polygon, sfdata)
  {
  polygon <- st_as_sf(polygon) # 
  st_crs(sfdata) <- st_crs(polygon) # makes coordinate reference systems equivalent
  polygon <- st_make_valid(polygon) # makes geometry valid
  ogeo <- st_intersection(sfdata, polygon)
  ogeo <- ogeo %>%
  dplyr::mutate(longitude = sf::st_coordinates(.)[,1],
                latitude = sf::st_coordinates(.)[,2]) %>% 
  st_drop_geometry(ogeo) %>% 
  dplyr::select(-c(id))
  return(ogeo)
}

my_mutate_distinct <- function(data, group_vars, summary_vars, ...) {
  stopifnot(
    is.list(group_vars),
    is.list(summary_vars)
  )
  
  args <- enquos(...)
  ex_args <- unname(imap(args, function(expr, name) quo(!!sym(name)==!!expr)))

  # Detect and prefix unnamed arguments:
  unnamed <- names(summary_vars) == ""

  # Add the default names:
  summary_vars <- rlang::quos_auto_name(summary_vars)

  prefixed_nms <- paste0("new_", names(summary_vars)[unnamed])
  names(summary_vars)[unnamed] <- prefixed_nms

  # Expand the argument _after_ giving the list its default names
  summary_vars <- purrr::map(summary_vars, function(var) {
    expr(paste_distinct(!!var))
  })

  data %>%
    group_by(!!!group_vars) %>%
    filter(!!!ex_args) %>% 
    mutate(n = n(), !!!summary_vars) %>% 
    fill(everything(), .direction = "down") %>%
    fill(everything(), .direction = "up")
}
```

## Workflow Image and Schema Image
```{r workflow, echo = FALSE}

```

# NMSU

Each dataset should have its own introduction and source references for how a person 
might go about finding this dataset - in this case a link to the herbarium website would work
and explain how to submit a request. but more so, explain what the data is and where it comes from

Questions for zack and sara: is this data complete? what is its purpose? how was it created?
how is it different than records uploaded to SEINet - is it uploaded elsewhere

Eventually I need to think about what needs to be reported and what needs to be an appendix
reported -> map of georeferenced records would be nice
the steps taken and 
table of records lost from each transformation

Editing notes to self: 
1) instead of using the index, it would be more readable to use all the column names
2) instead of turning to lowercase later, I could do it at the begining but it would require retyping a bunch of stuff
3) put all csv's to be read in at the beginning (exept the big dataframes)
```{r NMSU herbaria}
df <- read.csv("./repo_herb_original_tables/NMSU_herbaria_Dona_Ana_1.19.2022.csv", header = TRUE)

df$myid <- paste0(df$myid,'nmsu', seq.int(nrow(df))) # my ID

#write.csv(df, file.path(path, "nmsu_herbaria_dona_ana_1.19.2022_myid.csv"), row.names=FALSE)

df <- df[ c(1,2,10,13,14,15,16,21,22,39:88,94:96,101:104,126:129,144)] # subset

df <- housekeeping(df) # as character, lowercase, reduce blank spaces

# Add prefix to NMSU herbaria dataset so I can tell them apart from NMSU blm set
df <- df %>% 
  rename_with( ~ paste("OG", .x, sep = "_"))

```

```{r NMSU herbaria duplicates}
# Create duplicate count for select columns and create dupe ID
dfdupe <- df %>% 
  get_dupes(OG_AccessionNumber) %>% 
  mutate(within_inst_dupe_id = group_indices(., OG_AccessionNumber)) 

# dupe prefix id
dfdupe$within_inst_dupe_id <- paste0('wi_nmsu_', dfdupe$within_inst_dupe_id)

# Harmonize row wise filling all NA values
df <- df %>% 
  group_by(OG_AccessionNumber) %>% 
  fill(everything(), .direction = "down") %>%
  fill(everything(), .direction = "up") %>%
  slice(1)

# Create table tracking duplication
dupe_table <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, OG_myid, dupe_count, OG_HerbariumAcronyms) %>% 
  rename(institution = OG_HerbariumAcronyms, 
         og_myid= OG_myid)
```

```{r NMSU blm}
# Bring in Organ Mountain BLM dataset
df1 <- read.csv("./repo_herb_original_tables/OMBLM.csv", header = TRUE)
df1$myid <- paste0(df1$myid, 'nmsublm',seq.int(nrow(df1))) # ID

#write.csv(df1, file.path(path, "omblm_myid.csv"), row.names=FALSE)

df1 <- housekeeping(df1) # as character, lowercase, reduce blank spaces

names(df)[1] <- "AccessionNumber" # make this column match in order to merge 

df <- left_join(df1,df, by = "AccessionNumber") # join both by AccessionNumber
df <- df[ c(1:48,73:78,83,84,107:118)] # subset
```

## Harmonize and Prioritize Most Accurate Georeferencing Efforts
```{r NMSU coalesce, rename, drop columns}

# Records georeferenced using township range and section are most accurate for oldest records, followed by decimal minutes from UTM, then post factum georeferencing 
df <- df %>% 
  mutate(latitude = coalesce(OG_CalculatedLatitudeInDecimalMinutesFromTRS,
                           OG_CalculatedLatitudeInDecimalMinutesFromUTM,
                           DecDeg_Verb.Post_Factum_Latitude, LATITUDE)) %>% 
  mutate(longitude = coalesce(OG_CalculatedLongitudeInDecimalMinutesFromTRS,
                            OG_CalculatedLongitudeInDecimalMinutesFromUTM,
                            DecDeg_Verb.Post_Factum_Longitude, LONGITUDE)) %>% 
  rename(day = OG_CollectingStartDateDay,
         month = OG_CollectingStartDateMonth,
         year = OG_CollectingStartDateYear) %>% 
  mutate(collector = paste(df$OG_Collector1FirstName,df$OG_Collector1MiddleName, 
                           df$OG_Collector1LastName, sep= " ")) %>% 
  dplyr::select( -c(LATITUDE, OG_Latitude, DecDeg_Verb.Post_Factum_Latitude, LONGITUDE,
           OG_Longitude, DecDeg_Verb.Post_Factum_Longitude,
           OG_CalculatedLatitudeInDecimalMinutesFromUTM, 
           OG_CalculatedLatitudeInDecimalMinutesFromTRS,Collector, 
           OG_LatitudeRemark,OG_LongitudeRemark, OG_CollectionNumberAlphanumeric,
           OG_Collector1FirstName, OG_Collector1MiddleName,OG_Collector1LastName, 
           OG_LegacyDuplicateDistributionString, OG_DuplicateNumberOriginal, 
           MERIDIAN_FOR_TRS_CALC, TOWNSHIP_STANDARDIZED, RANGE_STANDARDIZED,
           SECTION_STANDARDIZED, Q_STANDARDIZED, Q1_STANDARDIZED, Q2_STANDARDIZED,
           TRS_TEXT_NOTE_STANDARDIZED,UTM_DATUM_STANDARDIZED, UTM_E_STANDARDIZED,
           UTM_N_STANDARDIZED, UTM_Z_STANDARDIZED, 
           OG_CalculatedLatitudeInDecimalMinutesFromTRS,
           OG_CalculatedLatitudeInDecimalMinutesFromUTM))

# for record keeping
sum(is.na(df$latitude)) # sum of NA values in New Latitude 131
131/2705 # %0.04842884 Latitude are NA
names(df) <- tolower(names(df))
```

## Separate Georeferenced Records
```{r NMSU locality georeferenced, message = FALSE, warning = FALSE}
# Parse latitude and Longitude
df$latitude <- parse_lat(df$latitude)
df$longitude <- parse_lon(df$longitude)

geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))
sfpoly <- st_read("./boundary_for_herbarium_occurences")

ogeo <- organ_location(sfpoly, sfdf)

# Record keeping
nrow(ogeo) # 1905 are georeferenced AND in the Organ Mountains polygon
nrow(geo)# 2574 are georeferenced
nrow(geo)/nrow(df) # 95% georeferenced
```

```{r NMSU locality non-georeferenced}
# Keep rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))

# Filter Non-Georeferenced records by string match
onotgeo <- notgeo %>% 
  filter_at(vars(location, abiotic_ecological, biotic_association, query_word, og_collectionremarksgeneral),
  any_vars(str_detect(.,".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

# Merge
ogeo <- ogeo[,order(names(ogeo))]
onotgeo <- onotgeo[,order(names(onotgeo))]
org <- rbind(onotgeo, ogeo)

# record keeping
nrow(onotgeo) # 131 Makes sense 
nrow(ogeo) # 1905
nrow(org) # 2036
nrow(org) / nrow(df)# 0.75 ~ 75% in Organ Mountains

# rename
df <- org

# for exporting csv's  rejected dataset if we want that
#reject <- anti_join(df, org, by = 'myid') # anti_join(x, y) return all rows from x without a match in y
#nrow(reject) # 669

#write.csv(reject,"atempt-3-nmsu_locality_reject.csv", row.names = FALSE)
#write.csv(org,"atempt-3-nmsu_intermediary.csv", row.names = FALSE)
```

## Clean Collector Names
```{r NMSU collector names}
df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)
# Get rid of spaces again
df <- str_squish_trim(df)

# I have to repeat this for "NA NA NA"
df$collector <- df$collector %>%
  str_remove("NA ") %>% 
  str_remove("NA") %>%
  str_remove("NA")

# Get rid of spaces again
df <- str_squish_trim(df)

# Fill NA's Back in and duplicate column
df <- df %>% 
  mutate_all(na_if,"") %>% 
  mutate(clean.collector = collector)

# Since the NMSU names are already very clean, I'm just modifying a 
# few so they match my dictionary in cases where my dictionary is more complete

df$clean.collector <- gsub("^bruce.*weber", "bruce e. weber", df$clean.collector)
df$clean.collector <- gsub("c. (mrs.) t. bartlett", "c. t. bartlett", df$clean.collector) 
df$clean.collector <- gsub("c. e. freeman", "craig freeman", df$clean.collector) 
df$clean.collector <- gsub(".*ulaszek", "eric f. ulaszek", df$clean.collector) 
df$clean.collector <- gsub(".*coons", "f. m. coons", df$clean.collector) 
df$clean.collector <- gsub(".*medler", "john medler", df$clean.collector) 
df$clean.collector <- gsub("^r. c. j.$", "raymond c. jackson", df$clean.collector) 
df$clean.collector <- gsub(".*anderson", "s. e. anderson", df$clean.collector) 

```

## Flag and Harmonize Duplicates
```{r NMUS blm dupes}
df <- df %>% 
  rename(eventdate = collection_date,
         colnumber = calc_coll_number)

# Generate duplicate count for select columns and create ID
# in this case I'm using the latitude longitude since most of them are 
# exactly the same otherwise I'd have to prioritize georeferencing efforts 
# which can happen in the last step
dfdupe <- df %>% 
  get_dupes(clean.collector, colnumber, location, eventdate, taxon, latitude, longitude) %>% 
  mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, location, 
                                   eventdate, taxon, latitude, longitude))


# dupe prefix id
dfdupe$within_inst_dupe_id <- paste0('wi_nmsublm_', dfdupe$within_inst_dupe_id)

# subeset previous duplicate table to only include those in organ filtered data
dupe_table <- semi_join(dupe_table, df, by = 'og_myid')

# Create another table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, og_herbariumacronyms) %>% 
  rename(institution = og_herbariumacronyms)


# rename to merge
dupe_table <- dupe_table %>% 
  rename(myid = og_myid)

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)

# replace NA's with nmc - in this case we know the institution
dupe_table$institution <- dupe_table$institution %>% replace_na('nmc')

# add data_source column
dupe_table$data_source <- "nmsu"

```

```{r NMSU blm harmonize}
# Harmonize row-wise based on unique duplicate ID
dfdupemerge <- dfdupe %>%
  group_by(within_inst_dupe_id) %>%
  fill(everything(), .direction = "down") %>%
  fill(everything(), .direction = "up") %>% 
  slice(1)

# Anti_join so that the main dataframe only has non duplicated records
df <- anti_join(df, dfdupe, by = 'myid') 

df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates

# Merge
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]
df <- rbind(df,dfdupemerge)
nrow(df) # 2016
```

## Standardize Schema
```{r NMSU schema, warning = FALSE, message = FALSE}
dictionary <- read.csv("./dictionaries/column_name_dictionary_03-06_22.csv", header = TRUE)
colnames <- names(df) 
colnames <- as.data.frame(colnames) # as dataframe

colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames

df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"

nmsu <- df #rename

# keep these objects
keep(nmsu, dupe_table, sfpoly, dictionary, organ_location, housekeeping, 
     str_squish_trim, conditional_dupes, my_mutate_distinct, paste_na, 
     paste_distinct, sure = TRUE)
```


# Consortia of Intermountain Regional Herbaria Network
```{r COIH rename and drop columns}
df <- read.csv("./repo_herb_original_tables/coih_original.csv", header = TRUE)
df$myid <- paste0(df$myid,'coih',seq.int(nrow(df)))

#write.csv(df, file.path(path, "coih_original_myid.csv"), row.names=FALSE)


df <- housekeeping(df)
df <- df[,colSums(is.na(df))<nrow(df)] # drop columns which are all NA
```

## Separate Georeferenced Records
```{r COIH locality georeferenced, warning = FALSE, message = FALSE}

df <- df %>% rename(longitude = decimalLongitude,
       latitude = decimalLatitude) %>% 
  dplyr::select(-c(id))

# Retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

# parse lat long
geo$latitude <- parse_lat(geo$latitude)
geo$longitude <- parse_lon(geo$longitude)

# drop NA
geo <- geo[!is.na(geo$latitude), ]
geo <- geo[!is.na(geo$longitude), ]


sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))
ogeo <- organ_location(sfpoly, sfdf)

# record keeping
nrow(geo)# 8808 rows
nrow(ogeo) # 2606
nrow(ogeo) / nrow(geo) # 0.29% of georeferenced records are within the Organs
```

## Separate Non-Georeferenced Records 
```{r COIH, warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))

onotgeo <- notgeo %>% 
  filter_at(vars(locality, locationRemarks, occurrenceRemarks, verbatimAttributes, municipality, associatedTaxa), 
  any_vars(str_detect(., ".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))


# merge
ogeo <- ogeo[,order(names(ogeo))]
onotgeo <- onotgeo[,order(names(onotgeo))]
org <- rbind(onotgeo, ogeo)

# record keeping
nrow(notgeo) # 15496
nrow(onotgeo) # 5794
nrow(onotgeo) / nrow(notgeo) # % 0.3739 of those not georeferenced match an Organ Mountain string search
nrow(org) # 8400
nrow(org)/ nrow(df)# 0.3456221 ~35%  in Organ Mountains
#reject <- anti_join(df, org, by = 'myid') # anti_join(x, y) return all rows from x without a match in y
```

## Clean Collector Names With Dictionary
```{r warning = FALSE, message = FALSE}
# rename
df <- org

dict <- read.csv("./dictionaries/collector_name_dictionary.csv", header = TRUE) # read in collector dictionary

# rename
df <- df %>% 
  dplyr::rename(taxon = scientificName,
         location = locality,
         eventdate = eventDate,
         colnumber = recordNumber,
         collector = recordedBy)

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)

df <- housekeeping(df)

# Apply collector name dictionary
df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) 

df$clean.collector <- gsub("\\d.*", "NA", df$clean.collector) # extra cleaning
# I might be deleting collector numbers here
```

## Flag and Harmonize Duplicates
```{r flag duplicates, warning = FALSE, message = FALSE, error = TRUE}
# create a column which indicates if the location description is blank. This will help me identify duplicates without erroneously assigning a dupliacte to a column which is duplicated only becasue of the "NA" in location
df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

# assign duplicates based on duplication in collector, date, collection number, and taxon
# but separate those that have NA's in the location - we don't want to group these as duplicates if they have no locality description
dfdupe <- conditional_dupes(na = df$na, df = df, df$location,  df$eventdate,
               df$clean.collector, df$taxon, df$colnumber)

# Duplicate ID
dfdupe <- dfdupe %>% 
  group_by(clean.collector, colnumber,eventdate, taxon, year) %>%  # group by this
    mutate(within_inst_dupe_id = cur_group_id())%>%  # make an id based on the grouping
  group_by(within_inst_dupe_id) %>% # group by id
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE))%>% # count georeferencing efforts
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything()) # bring this to the front

# make the duplicate id unique for coih
dfdupe$within_inst_dupe_id <- paste0('wi_coih_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, institutionCode) %>% 
  rename(institution = institutionCode)

# add data_source column
dupe_table_1$data_source <- "coih"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)

# record keeping
nrow(dupe_table) # 2161
```
                
Table summarizing the different types of harmonizing records and the decisions made for each column:

|Unique Values                 | All Values          | Fill NA's                |
|----------------------------- | --------------------|--------------------------|
|latitude                      | institutionCode     | country                  |
|longitude                     | myid                | county                   |
|associatedCollectors          | otherCatalogNumbers | verbatimTaxonRank        |
|associatedTaxa                | ownerInstitutionCode| typeStatus               |
|collectionCode                | catalogNumber       | taxonRank                |
|cultivationStatus             | id                  | taxonID                  |
|dateIdentified                |                     | basisOfRecord            |
|day                           |                     | stateProvince            |
|endDayOfYear                  |                     | sex                      |
|establishmentMeans            |                     | preparations             |
|georeferenceRemark            |                     | phylum                   |
|habitat                       |                     | order                    |
|identificationQualifier       |                     | identificationReferences |
|identificationRemarks         |                     | recordEnteredBy          |
|identifiedBy                  |                     | localitySecurity         |
|locationRemarks               |                     | language                 |
|month                         |                     | kingdom                  |
|occurrenceRemarks             |                     | recordEnteredBy          |
|reproductiveCondition         |                     | higherClassification     |
|startDayOfYear                |                     | family                   |
|substrate                     |                     | genus                    |
|verbatimAttributes            |                     | georeferencedBy          |
|verbatimCoordinates           |                     | class                    |
|verbatimElevation             |                     | fieldNumber              |
|verbatimEventDate             |                     | geodeticDatum            |
|year                          |                     | informationWithheld      |
|taxonRemarks                  |                     | sourcePrimaryKey.dbpk    |
|specificEpithet               |                     | references               |
|municipality                  |                     | recordId                 |
|lifeStage                     |                     | occurrenceID             |
|individualCount               |                     | modified                 |
|dynamicProperties             |                     |                          |
|disposition                   |                     |                          |
|collId                        |                     |                          |
|maximumElevationInMeters      |                     |                          |
|minimumElevationInMeters      |                     |                          |
|georeferenceProtocol          |                     |                          |   
|georeferenceSources           |                     |                          |
|georeferenceVerificationStatus|                     |                          |
|scientificNameAuthorship      |                     |                          |
|infraspecificEpithet          |                     |                          |
|collector                     |                     |                          |

```{r harmonize duplicates}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
  vars(associatedCollectors = associatedCollectors, 
       associatedTaxa = associatedTaxa, 
       collectionCode = collectionCode,
       cultivationStatus = cultivationStatus,
       dateIdentified = dateIdentified, 
       day = day, 
       endDayOfYear = endDayOfYear, 
       establishmentMeans = establishmentMeans, 
       georeferenceRemarks = georeferenceRemarks, 
       habitat = habitat, 
       identificationQualifier = identificationQualifier,
       identificationRemarks = identificationRemarks, 
       identifiedBy = identifiedBy,
       locationRemarks = locationRemarks, 
       month = month, 
       occurrenceRemarks = occurrenceRemarks,
       reproductiveCondition = reproductiveCondition, 
       startDayOfYear = startDayOfYear, substrate = substrate, verbatimAttributes = verbatimAttributes,
       verbatimCoordinates = verbatimCoordinates, verbatimElevation = verbatimElevation, 
       verbatimEventDate = verbatimEventDate,year = year,specificEpithet = specificEpithet, 
       taxonRemarks = taxonRemarks, municipality = municipality, lifeStage = lifeStage,
       individualCount = individualCount, dynamicProperties = dynamicProperties, 
       disposition = disposition, collId = collId, minimumElevationInMeters = minimumElevationInMeters,
       maximumElevationInMeters = maximumElevationInMeters, georeferenceProtocol= georeferenceProtocol,
       georeferenceSources = georeferenceSources, georeferenceVerificationStatus = georeferenceVerificationStatus,
       scientificNameAuthorship = scientificNameAuthorship, infraspecificEpithet = infraspecificEpithet, 
       collector = collector, myid = myid, institutionCode = institutionCode,otherCatalogNumbers = otherCatalogNumbers,
       ownerInstitutionCode = ownerInstitutionCode,catalogNumber = catalogNumber), loc_count = '0') %>% slice(1)



dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
  vars(associatedCollectors = associatedCollectors, associatedTaxa = associatedTaxa, 
       collectionCode = collectionCode,cultivationStatus = cultivationStatus,dateIdentified = dateIdentified, 
       day = day, endDayOfYear = endDayOfYear,establishmentMeans = establishmentMeans, 
       georeferenceRemarks = georeferenceRemarks, habitat = habitat, 
       identificationQualifier = identificationQualifier,identificationRemarks = identificationRemarks, 
       identifiedBy = identifiedBy,locationRemarks = locationRemarks, month = month, 
       occurrenceRemarks = occurrenceRemarks,reproductiveCondition = reproductiveCondition, 
       startDayOfYear = startDayOfYear, substrate = substrate, verbatimAttributes = verbatimAttributes,
       verbatimCoordinates = verbatimCoordinates, verbatimElevation = verbatimElevation, 
       verbatimEventDate = verbatimEventDate,year = year,specificEpithet = specificEpithet, 
       taxonRemarks = taxonRemarks, municipality = municipality, lifeStage = lifeStage,
       individualCount = individualCount, dynamicProperties = dynamicProperties, 
       disposition = disposition, collId = collId, minimumElevationInMeters = minimumElevationInMeters,
       maximumElevationInMeters = maximumElevationInMeters, georeferenceProtocol= georeferenceProtocol,
       georeferenceSources = georeferenceSources, georeferenceVerificationStatus = georeferenceVerificationStatus,
       scientificNameAuthorship = scientificNameAuthorship, infraspecificEpithet = infraspecificEpithet, 
       collector = collector, myid = myid, institutionCode = institutionCode, 
       otherCatalogNumbers = otherCatalogNumbers,ownerInstitutionCode = ownerInstitutionCode),
  loc_count = '1') %>% 
  filter(!is.na(latitude)) %>% slice(1)

dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)
```


```{r merge harmonized records}

df <- anti_join(df, dfdupe, by = 'myid') # anti_join so that the main dataframe does not include the duplicates
df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]

dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

df <- rbind(df,dfdupemerge)
```


## Standardize Schema
```{r warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
coih <- df #rename

keep(coih, nmsu, dupe_table, sfpoly, dictionary, dict, organ_location, 
     housekeeping, str_squish_trim, conditional_dupes,
     my_mutate_distinct, paste_na, paste_distinct, sure = TRUE)
```

# GBIF
```{r warning = FALSE, message = FALSE}
df <- read.csv("./repo_herb_original_tables/gbif_original.csv", header = TRUE)
df$myid <- paste0(df$myid,'gbif',seq.int(nrow(df)))

#write.csv(df, file.path(path, "gbif_original_myid.csv"), row.names=FALSE)
df <- housekeeping(df)
```
## Separate Georeferenced Records
rename columns for ease, replace empty cells with NA
```{r warning = FALSE, message = FALSE}
df <- df %>% 
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude,
         collector = recordedBy,
         taxon = scientificName,
         location = locality,
         eventdate = eventDate,
         colnumber = recordNumber)

#retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

geo$latitude <- parse_lat(geo$latitude)
geo$longitude <- parse_lon(geo$longitude)

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))

ogeo <- organ_location(sfpoly, sfdf) # nrow 5228
```

## Separate Non-Georeferenced Records
```{r warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))
nrow(notgeo) # only 2 records not georeferenced

onotgeo <- notgeo %>% 
  filter_all(all_vars(str_detect(.,".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

nrow(notgeo) # 2 before and  0 after string search
nrow(onotgeo) # 0
nrow(ogeo) # 5228
nrow(ogeo) / nrow(df) #  0.1851734 ~19% in Organ Mountains
reject <- anti_join(df, ogeo, by = 'myid') # anti_join(x, y) return all rows from x without a match in y
nrow(reject) # 23005
```

## Clean Collector Names With Dictionary
```{r warning = FALSE, message = FALSE}
df <- ogeo

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)

df <- housekeeping(df)

df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) # apply collector name dictionary
```

## Flag and Harmonize Duplicates
```{r flag dupes, warning = FALSE, message = FALSE}

df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

dfdupe <- conditional_dupes(na = df$na, df = df, df$location, df$eventdate, 
               df$clean.collector, df$taxon, df$colnumber)

dfdupe <- dfdupe %>% 
    mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, year, location, 
                                   eventdate, taxon)) %>% 
  group_by(within_inst_dupe_id) %>%
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE)) %>% 
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything())

dfdupe$within_inst_dupe_id <- paste0('wi_gbif_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, institutionCode) %>% 
  rename(institution = institutionCode)

# add data_source column
dupe_table_1$data_source <- "gbif"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)

# record keeping
nrow(dupe_table) # 2431
```
Table summarizing the different types of harmonizing records and the decisions made for each column:

|Unique Values                   | All Values      | Fill NA's                    |
|------------------------------- | ----------------|------------------------------|
|latitude                        | catalogNumber   | countryCode                  |
|longitude                       | institutionCode | class                        |
|dateIdentified                  | myid            | phylum                       |
|day                             | collectionCode  | order                        |
|elevation                       |                 | genus                        |
|elevationAccuracy               |                 | family                       |
|establishmentMeans              |                 | depth                        |
|identifiedBy                    |                 | depthAccuracy                |
|individualCount                 |                 | scientificName               |
|issue                           |                 | kingdom                      |
|lastInterpreted                 |                 | typeStatus                   |
|mediaType                       |                 | stateProvince                |
|month                           |                 | taxonRank                    |
|collector                       |                 | taxonKey                     |
|verbatimScientificName          |                 | speciesKey                   |
|verbatimScientificNameAuthorship|                 | publishingOrgKey             |
|year                            |                 | occurrenceStatus             |
|rightsHolder                    |                 | occurrenceID                 |
|license                         |                 | gbifID                       |
|infraspecificEpithet            |                 | datasetKey                   |
|                                |                 | coordinateUncertaintyInMeters|
|                                |                 | coordinatePrecision          |
|                                |                 | basisOfRecord                


These ones I want all values - return
institutionCode = institutionCode,
collectionCode = collectionCode,
catalogNumber = catalogNumber
```{r warning = FALSE, message = FALSE}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(dateIdentified = dateIdentified,day = day,
                                 elevation = elevation,
                                 elevationAccuracy = elevationAccuracy,
                                 establishmentMeans = establishmentMeans,
                                 identifiedBy = identifiedBy,
                                 individualCount = individualCount,
                                 issue = issue,lastInterpreted = lastInterpreted,
                                 mediaType = mediaType,month = month,collector = collector,
                                 verbatimScientificName = verbatimScientificName,
                                 verbatimScientificNameAuthorship = verbatimScientificNameAuthorship,year = year,
                                 rightsHolder = rightsHolder,license = license,infraspecificEpithet = infraspecificEpithet,
                                 myid = myid,institutionCode = institutionCode,collectionCode = collectionCode,
                                 catalogNumber = catalogNumber), loc_count = '0') %>% slice(1)

# if one lat long and one NA keep the lat long for everything
dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(dateIdentified = dateIdentified,day = day,
                                 elevation = elevation,elevationAccuracy = elevationAccuracy,
                                 establishmentMeans = establishmentMeans,identifiedBy = identifiedBy,
                                 individualCount = individualCount,issue = issue,lastInterpreted = lastInterpreted,
                                 mediaType = mediaType,month = month,collector = collector,
                                 verbatimScientificName = verbatimScientificName,
                                 verbatimScientificNameAuthorship = verbatimScientificNameAuthorship,year = year,
                                 rightsHolder = rightsHolder,license = license,infraspecificEpithet = infraspecificEpithet,
                                 myid = myid,institutionCode = institutionCode,collectionCode = collectionCode,
                                 catalogNumber = catalogNumber), loc_count = '1') %>% 
  filter(!is.na(latitude)) %>% 
  slice(1) 

dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)

# For whatever reason there are three groups of duplicates 
# with multiple georeferencing efforts but NA's in most relevent categories
# these will probebly be dropped in th end


df <- anti_join(df, dfdupe, by = 'myid') # anti_join so that the main dataframe does not include the duplicates
df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"

dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

# merge
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]
df <- rbind(df,dfdupemerge)
nrow(df) # 5167
```

## Standardize Schema
```{r warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
gbif <- df #rename
keep(sfpoly, coih, nmsu,gbif, dupe_table, dictionary, dict, organ_location, housekeeping, str_squish_trim, conditional_dupes,my_mutate_distinct, paste_na, paste_distinct, sure = TRUE)
```

# SEINET
```{r warning = FALSE, message = FALSE}
df <- read.csv("./repo_herb_original_tables/seinet_original_copy.csv", header = TRUE) 
df$myid <- paste0(df$myid,'seinet',seq.int(nrow(df))) # add personal ID

#write.csv(df, file.path(path, "seinet_original_myid.csv"), row.names=FALSE)

df <- housekeeping(df)
```

## Separate Georeferenced Records
```{r warning = FALSE, message = FALSE}
df <- df %>% 
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude, 
         collector = recordedBy,
         taxon = scientificName_occurrence,
         location = locality,
         eventdate = eventDate,
         colnumber = recordNumber)

#retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

geo <- geo[!is.na(geo$latitude), ] # drop all NA for latitude
geo <- geo[!is.na(geo$longitude), ] # drop all NA for longitude

geo$latitude <- parse_lat(geo$latitude) # parse / clean lat
geo$longitude <- parse_lon(geo$longitude) # parse / clean long

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))

ogeo <- organ_location(sfpoly, sfdf)
```

## Separate Non-Georeferenced Records 
```{r warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.))) # filter for records without lat long

onotgeo <- notgeo %>% 
  filter_at(vars(location, municipality, occurrenceRemarks, habitat), 
  any_vars(str_detect(.,".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

nrow(notgeo) # 14325 records not georeferenced 
nrow(onotgeo) # 5143 records matching strings and not georeferenced
nrow(onotgeo) / nrow(notgeo) # 0.3590227 ~ 36% of the non-georeferenced records contained a string match from my list of Organ Mountains place name terms
```

## Join Georeferenced and Non-Georeferenced Datasets Together
```{r warning = FALSE, message = FALSE}
ogeo <- ogeo[,order(names(ogeo))] # order columns alphabetically
onotgeo <- onotgeo[,order(names(onotgeo))] # order columns alphabetically

org <- rbind(onotgeo, ogeo) # combine
nrow(org) # 7756 total records filtered for Organs

nrow(org) / nrow(df) # 0.3242068 ~ 32% in Organ Mountains
reject <- anti_join(df, org, by = 'myid') # anti_join(x, y) return all rows from x without a match in y
nrow(reject) # 16167
```

## Clean Collector Names With Dictionary
```{r warning = FALSE, message = FALSE}
df <- org

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)

df <- housekeeping(df)

df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) # apply collector name dictionary

df$clean.collector <- gsub("\\d.*", "NA", df$clean.collector) # extra cleaning
```

## Flag and Harmonize Duplicates
```{r warning = FALSE, message = FALSE}
df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

dfdupe <- conditional_dupes(na = df$na, df = df, df$location, df$eventdate, 
               df$clean.collector, df$taxon, df$colnumber)

dfdupe <- dfdupe %>% 
    mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, location, 
                                   eventdate, taxon))%>% 
  group_by(within_inst_dupe_id) %>%
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE))%>% 
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything())

dfdupe$within_inst_dupe_id <- paste0('wi_seinet_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, institutionCode) %>% 
  rename(institution = institutionCode)

# add data_source column
dupe_table_1$data_source <- "seinet"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)

# record keeping
nrow(dupe_table) # 2973

```

Table summarizing the different types of harmonizing records and the decisions made for each column:

|Unique Values                | All Values      | Fill NA's          |
|---------------------------- | ----------------|--------------------|
|latitude                     | institutioncode | country            |
|longitude                    | myid            | county             |
|associatedTaxa               | catalognumber   | collid             |
|dateIdentified               | occid           | collectioncode     |
|occurrenceRemarks            | references      | stateProvince      |
|reproductivecondition        |                 | family occurrence  |
|verbatimelevation            |                 | informationWithheld|
|habitat                      |                 | recordID           |
|municipality                 |                 | othercatalognumbers|
|collector                    |                 | occurenceID        |
|identifiedBy                 |                 |                    |
|coordinateuncertaintyinmeters|                 |                    |                 
|locality security            |                 |                    |                   
|maximumelevationinmeters     |                 |                    |  
|minimumElevationInMeters     |                 |                    |

Come back for these
institutionCode = institutionCode,
occid = occid,
catalogNumber = catalogNumber,
references = references
```{r warning = FALSE, message = FALSE}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(associatedTaxa = associatedTaxa,dateIdentified = dateIdentified,
                                 occurrenceRemarks = occurrenceRemarks,
                                 reproductivecondition = reproductivecondition,
                                 verbatimelevation = verbatimelevation,
                                 habitat = habitat,municipality = municipality,
                                 collector = collector,
                                 reproductivecondition = reproductivecondition,
                                 identifiedBy = identifiedBy,
                                 maximumelevationinmeters = maximumelevationinmeters,
                                 minimumElevationInMeters = minimumElevationInMeters,
                                 localitysecurity = localitysecurity,
                                 coordinateUncertaintyInMeters = coordinateUncertaintyInMeters,
                                 myid = myid,institutionCode = institutionCode,
                                 occid = occid,catalogNumber = catalogNumber,
                                 references = references), loc_count = '0') %>% slice(1)

dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(associatedTaxa = associatedTaxa,dateIdentified = dateIdentified,
                                 occurrenceRemarks = occurrenceRemarks,
                                 reproductivecondition = reproductivecondition,
                                 verbatimelevation = verbatimelevation,
                                 habitat = habitat,municipality = municipality,
                                 collector = collector,
                                 reproductivecondition = reproductivecondition,
                                 identifiedBy = identifiedBy,
                                 maximumelevationinmeters = maximumelevationinmeters,
                                 minimumElevationInMeters = minimumElevationInMeters,
                                 localitysecurity = localitysecurity,
                                 coordinateUncertaintyInMeters = coordinateUncertaintyInMeters,
                                 myid = myid,institutionCode = institutionCode,
                                 occid = occid,catalogNumber = catalogNumber,
                                 references = references), loc_count = '1') %>% 
  filter(!is.na(latitude)) %>% slice(1)

dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)

df <- anti_join(df, dfdupe, by = 'myid') # anti_join so that the main dataframe does not include the duplicates

df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"

df <- df[,order(names(df))] # order columns alphabetically 
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))] # order columns alphabetically 

dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

df <- rbind(df,dfdupemerge)

df <- df %>% 
  filter(!str_detect(county, '^dougl.*')) # remove douglas county records

```

## Standardize Schema
```{r warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
seinet <- df #rename

keep(seinet, coih, nmsu, gbif, dupe_table, dict, sfpoly, dictionary, 
     organ_location, housekeeping, str_squish_trim, conditional_dupes, 
      my_mutate_distinct, paste_na, paste_distinct, 
     sure = TRUE)
```

# Smithsonian
```{r}
df <- read.csv("./repo_herb_original_tables/smithsonian_original.csv", header = TRUE)
df$myid <- paste0(df$myid,'smith',seq.int(nrow(df)))

#write.csv(df, file.path(path, "smith_original_myid.csv"), row.names=FALSE)

df <- housekeeping(df)
df <- df[,colSums(is.na(df))<nrow(df)] # remove columns that are all NA's
```
## Separate Georeferenced Records
```{r warning = FALSE, message = FALSE}

df <- df %>% 
  rename(longitude = Centroid.Longitude,
         latitude = Centroid.Latitude, 
         collector = Collector.s.,
         taxon = Taxonomic.Name..Filed.As...Identified.By...Identification.Date.,
         location = Precise.Locality,
         eventdate = Date.Collected,
         colnumber = Collection.Number)

#retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

geo$latitude <- parse_lat(geo$latitude)
geo$longitude <- parse_lon(geo$longitude)

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))
ogeo <- organ_location(sfpoly, sfdf)

```

## Separate Non-Georeferenced Records 
```{r warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))
nrow(notgeo) # 604


onotgeo <- notgeo %>% 
  filter_at(vars(location, Notes, Microhabitat.Description, Habit, District.County, Province.State, Biogeographic.Region, Collection.Remarks,Other.Taxonomic.Names..Identification...Identified.By...Date.Identified., Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation.),
  any_vars(str_detect(.,".*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

nrow(onotgeo) # 240
nrow(onotgeo) / nrow(notgeo) # 0.397351, 39% matching Organs locality placename search of all non-georeferenced records
nrow(ogeo) # 118

ogeo <- ogeo[,order(names(ogeo))]
onotgeo <- onotgeo[,order(names(onotgeo))]

org <- rbind(onotgeo, ogeo)
nrow(org) # 358
nrow(org) / nrow(df) # 0.4508816 ~ 45%in Organ Mountains

reject <- anti_join(df, org, by = 'myid') # anti_join(x, y) return all rows from x without a match in y
nrow(reject) # 436
```

## Clean Collector Names With Dictionary
```{r warning = FALSE, message = FALSE}
df <- org

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)
df <- housekeeping(df)

df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) # apply collector name dictionary
```
## Flag and Harmonize Duplicates
```{r warning = FALSE, message = FALSE}
df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

dfdupe <- conditional_dupes(na = df$na, df = df, df$location, df$eventdate, 
               df$clean.collector, df$taxon, df$colnumber)

dfdupe <- dfdupe %>% 
    mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, location, 
                                   eventdate, taxon)) %>% 
  group_by(within_inst_dupe_id) %>%
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE))%>% 
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything())

dfdupe$within_inst_dupe_id <- paste0('wi_smith_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count)

# add data_source column
dupe_table_1$data_source <- "smithsonian"
dupe_table_1$institution <- "smithsonian"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)

# record keeping
nrow(dupe_table) # 3009

```
Table summarizing the different types of harmonizing records and the decisions made for each column:

|Unique Values           | All Values               | Fill NA's                     |
|----------------------- | -------------------------|-------------------------------|
|latitude                |Catalog.Number            |Barcode                        |
|longitude               |myid                      |Biogeographic.Region           |
|Elevation..m.           |EZID                      |Biorepository.Number           |
|Common.Name..Name...L   |                          |Embargo.                       |
|Catalog                 |                          |Conservation.Status.Authority.S|
|collector               |                          |Country                        |
|Type.Citations..S....   |                          |District.County                |
|Record.Last.Modified    |                          |Family                         |
|Habit                   |                          |Genetic.Sample.Type            |
|Microhabitat.Description|                          |Name.Hierarchy                 |
|Notes                   |                          |Order                          |
|                        |                          |Subfamily                      |   
|                        |                          |Tribe                          |
|                        |                          |Taxonomy.Remarks               |
|                        |                          |Storage.Location               |
|                        |                          |Preservation.Method            |
|                        |                          |Other.Taxonomic.Names..Iified. |
|                        |                          |Other.Counts..Type...Value.    |
|                        |                          |Lectotypified.By               |
|                        |                          |Field.Id.Number                |
|                        |                          |Province.State                 |
|                        |                          |Collection.Remarks             |
|                        |                          |Other.Numbers..Type .Value     |
|                        |                          |                               |

Catalog.Number = Catalog.Number
EZID = EZID,
```{r warning = FALSE, message = FALSE}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(Elevation..m. = Elevation..m.,
                                 Common.Name..Name...Language. = Common.Name..Name...Language.,
                                 Catalog = Catalog,collector = collector,Habit = Habit,
                                 Microhabitat.Description = Microhabitat.Description,
                                 Notes = Notes,
                                 Record.Last.Modified = Record.Last.Modified,
                                 Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation. = Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation.,myid = myid,
                                 Catalog.Number = Catalog.Number,EZID = EZID), loc_count = '0') %>% slice(1)

dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(Elevation..m. = Elevation..m.,
                                 Common.Name..Name...Language. = Common.Name..Name...Language.,
                                 Catalog = Catalog,collector = collector,Habit = Habit,
                                 Microhabitat.Description = Microhabitat.Description,
                                 Notes = Notes,
                                 Record.Last.Modified = Record.Last.Modified,
                                 Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation. = Type.Citations..Scientific.Name...Type.Status...Verification.Degree...Citation.,myid = myid,
                                 Catalog.Number = Catalog.Number,EZID = EZID), loc_count = '1') %>% 
  filter(!is.na(latitude)) %>% slice(1)

dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)

df <- anti_join(df, dfdupe, by = 'myid') # anti_join so that the main dataframe does not include the duplicates

df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"

# merge
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]

dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

df <- rbind(df,dfdupemerge)

```
## Standardize Schema
```{r warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
smith <- df #rename

keep(sfpoly,seinet, smith, coih, nmsu, dupe_table, gbif, dict,dictionary, 
     organ_location, housekeeping, str_squish_trim, conditional_dupes, 
     my_mutate_distinct, paste_na, paste_distinct, 
     sure = TRUE)
```

# UTEP
[geosearch](https://arctos.database.museum/saved/1643063047101)
[nongeosearch](https://arctos.database.museum/saved/1643063152809)
```{r warning = FALSE, message = FALSE, include = FALSE}
df1 <- read.csv("./repo_herb_original_tables/utep_requery_3.csv", header = TRUE) 
df2 <- read.csv("./repo_herb_original_tables/utep_requery_4.csv", header = TRUE) 
df <- rbind(df1,df2)
nrow(df) # 11207
df$myid <- paste0(df$myid,'utep',seq.int(nrow(df)))

#write.csv(df, file.path(path, "utep_original_myid.csv"), row.names=FALSE)


df <- housekeeping(df)
df <- df[,colSums(is.na(df))<nrow(df)] # remove columns that are all NA's
```

## Separate Georeferenced Records
```{r warning = FALSE, message = FALSE}

df <- df %>% 
  dplyr::rename(taxon = SCIENTIFIC_NAME,
         location = SPEC_LOCALITY,
         eventdate = VERBATIM_DATE,
         colnumber = OTHERCATALOGNUMBERS,
         collector = COLLECTORS,
         latitude = DEC_LAT,
         longitude = DEC_LONG)

#retain rows with latitude and longitude values
geo <- df %>%
  filter_at(vars(latitude,longitude),any_vars(!is.na(.)))

geo$latitude <- parse_lat(geo$latitude)
geo$longitude <- parse_lon(geo$longitude)
nrow(geo)# 11086 records are georeferenced

sfdf <- st_as_sf(geo, coords = c("longitude", "latitude"))

ogeo <- organ_location(sfpoly, sfdf)
nrow(ogeo) #3200
```

## Separate Non-Georeferenced Records 
```{r warning = FALSE, message = FALSE}
#retain rows without latitude and longitude
notgeo <- df %>% 
  filter_at(vars(latitude,longitude),any_vars(is.na(.)))
nrow(notgeo) # 121

onotgeo <- notgeo %>% 
  filter_at(vars(COLORS, IDENTIFICATION_REMARKS, location, VERBATIM_LOCALITY, ASSOCIATED_SPECIES,LOCALITY_REMARKS, HABITAT, VERBATIM_COORDINATES),
  any_vars(str_detect(.,"'.*organ.*|.*orag.*|.*oregan.*|
  .*rgan.*|.*soladad.*|.*dripping.*|.*blanca.*|.*blanco.*|.*modoc.*|.*cuevas.*|.*quevos.*|.*achenb.*|.*finley.*|.*herbert.*|.*needle.*|.*rabbit.*|.*rabit.*|.*baylor.*|.*solidad.*|.*aguire.*|.*bishop.*|.*soledad.*|.*filmor|.*fillmore.*|.*achenb.*|.*zink.*|.*ice.*|.*poor mans friend.*|.*ruby mine.*|.*silver cliff.*|.*squaw mountain.*|.*sugar loaf peak.*|.*trapezoid prospect.*|.*mans canyon.*")))

nrow(onotgeo) #  21
ogeo <- ogeo[,order(names(ogeo))]
onotgeo <- onotgeo[,order(names(onotgeo))]
org <- rbind(onotgeo, ogeo)
nrow(org) # 3221
nrow(org) / nrow(df) # 0.2874097  29% in Organ Mountains
reject <- anti_join(df, org, by = 'myid') # anti_join(x, y) return all rows from x without a match in y
nrow(reject) # 7986

#write.csv(reject,"atempt-3-utep_locality_reject.csv", row.names = FALSE)
#write.csv(org,"atempt-3-utep_intermediary.csv", row.names = FALSE)

```

## Clean Collector Names With Dictionary
```{r warning = FALSE, message = FALSE}
df <- org

df$collector <- df$collector %>%
  str_remove("collector\\(s\\):") 

df$collector <- gsub("\\[no data available\\]|\\[data not captured\\]|.*collector.*|.*unk.*|.*anonym.*|.*unspecif.*
                     |^illegibl.*|.*dispon.*|\\?.*", "NA", df$collector)

df <- housekeeping(df)

df$clean.collector <- match_vec(df$collector, 
                          dictionary = dict, 
                          from = "keys", 
                          to = "values",
                          quiet = TRUE,
                          anchor_regex = TRUE,
                          warn_default = FALSE
                          ) # apply collector name dictionary

```

## Flag and Harmonize Duplicates
```{r warning = FALSE, message = FALSE}

df <- df %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE))

dfdupe <- conditional_dupes(na = df$na, df = df, df$location, df$eventdate, 
               df$clean.collector, df$taxon, df$colnumber)

dfdupe <- dfdupe %>% 
    mutate(within_inst_dupe_id = group_indices(., clean.collector, colnumber, 
                                   YEAR_COLLECTED,location, 
                                   eventdate, taxon)) %>% 
  group_by(within_inst_dupe_id) %>%
  mutate(loc_count = n_distinct(latitude, na.rm = TRUE))%>% 
  dplyr::select(within_inst_dupe_id, loc_count, taxon, location, 
                latitude, longitude, everything())

dfdupe$within_inst_dupe_id <- paste0('wi_utep_', dfdupe$within_inst_dupe_id)

# Create table tracking duplication
dupe_table_1 <- dfdupe %>% 
  dplyr::select(within_inst_dupe_id, myid, dupe_count, GUID) %>% 
  rename(institution = GUID)

# add data_source column
dupe_table_1$data_source <- "utep"

# bind the two dupe tables
dupe_table <- rbind(dupe_table_1, dupe_table)

# record keeping
nrow(dupe_table) # 6215

```

Table summarizing the different types of harmonizing records and the decisions made for each column:

|Unique Values                | All Values         | Fill NA's                    |
|---------------------------- | -------------------|------------------------------|
|latitude                     |myid                |ID_HISTORY                    |
|longitude                    |CATALOGNUMBERINT    |USE_LICENSE_URL               |
|ABUNDANCE                    |GUID                |STATE_PROV                    |
|ASSOCIATED_SPECIES           |                    |GENUS                         |
|ORIG_LAT_LONG_UNITS          |                    |FAMILY                        |
|collector                    |                    |COUNTRY                       |
|COLORS                       |                    |SPECIMEN_EVENT_REMARK         |
|ELEV_IN_M                    |                    |                              |
|GEOREFERENCE_SOURCE          |                    |                              |
|GEOREFERENCE_PROTOCOL        |                    |                              |
|HABITAT                      |                    |                              |
|MINIMUM_ELEVATION            |                    |                              |
|IDENTIFICATION_REMARKS       |                    |                              |
|IDENTIFIED_BY                |                    |                              |
|LOCALITY_REMARKS             |                    |                              |
|ORIG_ELEV_UNITS              |                    |                              |
|VERBATIM_COLLECTOR           |                    |                              |
|VERBATIM_COORDINATES         |                    |                              |
|VERBATIM_DATE                |                    |                              |
|COORDINATEUNCERTAINTYINMETERS|                    |                              |
|DAY_COLLECTED                |                    |                              |
|MAX_ELEV_IN_M                |                    |                              |
|MAXIMUM_ELEVATION            |                    |                              |
|SCI_NAME_WITH_AUTH           |                    |                              |
|MIN_ELEV_IN_M                |                    |                              |
|MONTH_COLLECTED              |                    |                              |
|YEAR_COLLECTED               |                    |                              |
|SPECIES                      |                    |                              |   
|SUBSPECIES                   |                    |                              |
|VERBATIM_LOCALITY            |                    |                              |



GUID = GUID,
CATALOGNUMBERINT = CATALOGNUMBERINT,
```{r warning = FALSE, message = FALSE}

dupe1 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(ABUNDANCE = ABUNDANCE,
                                 ASSOCIATED_SPECIES = ASSOCIATED_SPECIES,
                                 collector = collector,
                                 ORIG_LAT_LONG_UNITS = ORIG_LAT_LONG_UNITS,
                                 COLORS = COLORS,ELEV_IN_M = ELEV_IN_M,
                                 GEOREFERENCE_SOURCE = GEOREFERENCE_SOURCE,
                                 GEOREFERENCE_PROTOCOL = GEOREFERENCE_PROTOCOL,
                                 HABITAT = HABITAT,
                                 MINIMUM_ELEVATION = MINIMUM_ELEVATION,
                                 IDENTIFICATION_REMARKS = IDENTIFICATION_REMARKS,
                                 IDENTIFIED_BY = IDENTIFIED_BY,
                                 LOCALITY_REMARKS = LOCALITY_REMARKS,
                                 ORIG_ELEV_UNITS = ORIG_ELEV_UNITS,
                                 VERBATIM_COLLECTOR = VERBATIM_COLLECTOR,
                                 VERBATIM_COORDINATES = VERBATIM_COORDINATES,
                                 COORDINATEUNCERTAINTYINMETERS = COORDINATEUNCERTAINTYINMETERS,
                                 DAY_COLLECTED = DAY_COLLECTED,
                                 MAX_ELEV_IN_M = MAX_ELEV_IN_M,
                                 MAXIMUM_ELEVATION = MAXIMUM_ELEVATION,
                                 SCI_NAME_WITH_AUTH = SCI_NAME_WITH_AUTH,
                                 MIN_ELEV_IN_M = MIN_ELEV_IN_M,
                                 MONTH_COLLECTED = MONTH_COLLECTED,
                                 YEAR_COLLECTED = YEAR_COLLECTED,
                                 VERBATIM_LOCALITY = VERBATIM_LOCALITY,
                                 SUBSPECIES = SUBSPECIES,
                                 myid = myid,GUID = GUID,CATALOGNUMBERINT = CATALOGNUMBERINT), 
                            loc_count = '0') %>% slice(1)

dupe2 <- my_mutate_distinct(dfdupe, vars(within_inst_dupe_id), 
                            vars(ABUNDANCE = ABUNDANCE,
                                 ASSOCIATED_SPECIES = ASSOCIATED_SPECIES,
                                 collector = collector,
                                 ORIG_LAT_LONG_UNITS = ORIG_LAT_LONG_UNITS,
                                 COLORS = COLORS,ELEV_IN_M = ELEV_IN_M,
                                 GEOREFERENCE_SOURCE = GEOREFERENCE_SOURCE,
                                 GEOREFERENCE_PROTOCOL = GEOREFERENCE_PROTOCOL,
                                 HABITAT = HABITAT,
                                 MINIMUM_ELEVATION = MINIMUM_ELEVATION,
                                 IDENTIFICATION_REMARKS = IDENTIFICATION_REMARKS,
                                 IDENTIFIED_BY = IDENTIFIED_BY,
                                 LOCALITY_REMARKS = LOCALITY_REMARKS,
                                 ORIG_ELEV_UNITS = ORIG_ELEV_UNITS,
                                 VERBATIM_COLLECTOR = VERBATIM_COLLECTOR,
                                 VERBATIM_COORDINATES = VERBATIM_COORDINATES,
                                 COORDINATEUNCERTAINTYINMETERS = COORDINATEUNCERTAINTYINMETERS,
                                 DAY_COLLECTED = DAY_COLLECTED,
                                 MAX_ELEV_IN_M = MAX_ELEV_IN_M,
                                 MAXIMUM_ELEVATION = MAXIMUM_ELEVATION,
                                 SCI_NAME_WITH_AUTH = SCI_NAME_WITH_AUTH,
                                 MIN_ELEV_IN_M = MIN_ELEV_IN_M,
                                 MONTH_COLLECTED = MONTH_COLLECTED,
                                 YEAR_COLLECTED = YEAR_COLLECTED,
                                 VERBATIM_LOCALITY = VERBATIM_LOCALITY,
                                 SUBSPECIES = SUBSPECIES,
                                 myid = myid,GUID = GUID,CATALOGNUMBERINT = CATALOGNUMBERINT), 
                            loc_count = '1') %>% filter(!is.na(latitude)) %>% slice(1)


dupe3 <- dfdupe %>% 
  group_by(within_inst_dupe_id) %>%
  filter(loc_count > 1)

dfdupemerge <- rbind(dupe1,dupe2,dupe3)

df <- anti_join(df, dfdupe, by = 'myid') # anti_join so that the main dataframe does not include the duplicates

df$dupe_count <- "NA" # add columns added for duplicates
df$within_inst_dupe_id <- "NA" # add columns added for duplicates
df$loc_count <- "NA"
df <- df[,order(names(df))]
dfdupemerge <- dfdupemerge[,order(names(dfdupemerge))]
dfdupemerge <- dfdupemerge %>% 
  dplyr::select(-c(n))

df <- rbind(df,dfdupemerge)
```

## Standardize Schema
```{r warning = FALSE, message = FALSE}
colnames <- names(df) # make new dataframe of just column names
colnames <- as.data.frame(colnames) # as dataframe
colnames <- match_df(colnames, # match to column name dictionary
  dictionary = dictionary,
  from = "options",
  to = "values",
  by = "grp"
)

names(df) <- colnames$colnames # rename dataframe based on fixed colnames
df <- df[ , -which(names(df) %in% c("drop"))] # delete columns named "drop"
utep <- df #rename

keep(dupe_table, seinet, utep, smith, coih, nmsu, gbif, sfpoly, dict, 
     dictionary, organ_location, housekeeping, str_squish_trim, 
     conditional_dupes, my_mutate_distinct, 
     paste_na, paste_distinct, sure = TRUE)
```

# Combine Data Sets
```{r combine data sets}
df <- rbindlist(list(as.data.frame(nmsu),
                   as.data.frame(gbif),
                   as.data.frame(seinet),
                   as.data.frame(smith),
                   as.data.frame(coih),
                   as.data.frame(utep)),
                  fill=TRUE)

df <- as.data.frame(df)
df <- df[,order(names(df))]
nrow(df) # 24747

# I would like just one myid value. for the records which were not harmonized they keep original id
# for the ones that were harmonized for which each record represents multiple records that are squished
# for these i want the dupe id in to be myid that way you can look it up in the table and find all original records associated with that duplicate id

df$myid <- gsub(".*,.*", NA, df$myid)

df <-df %>% 
  mutate(myid = coalesce(myid, within_inst_dupe_id))
```

```{r misc cleaning}

# column names lowercase
names(df) <- tolower(names(df))

# fix dates in this column
df$verbatim_date <- gsub(".*no.*|^s.d.$|^unk.*|^#.*", "NA", df$verbatim_date)

# coalesce and paste to reduce redundant columns
df <- df %>% 
  dplyr::select(-c(na, myid.1)) %>% 
  mutate(taxon = coalesce(taxon, verbatim_sci_name)) %>% 
  mutate(collection_date = coalesce(collection_date, verbatim_date)) %>% 
  mutate(na = ifelse(is.na(df$location), TRUE, FALSE)) %>% 
  mutate(phenology = coalesce(phenology, phenology.1)) %>% 
  mutate(id_history = paste_na(df$id_history, df$id_history.1,
                               df$id_history.2)) %>% 
  mutate(misc_notes = paste_na(df$misc_notes, df$misc_notes.1)) %>% 
  mutate(morphological = paste_na(df$morphological,df$misc_notes.2)) %>% 
  dplyr::select( -c(misc_notes.2, id_history.1, id_history.2, notes.1, 
             taxon_key, species_key, dupe_count, phenology.1, misc_notes.1, 
             loc_count, common_name))
names(df)


write_excel_csv(df, "all_six_herbaria_combined_07_16_22.csv")
write_excel_csv(dupe_table, "within_institutions_dupelicates.csv")
```



